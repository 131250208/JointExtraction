{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from IPython.core.debugger import set_trace\n",
    "from pprint import pprint\n",
    "import unicodedata\n",
    "from transformers import AutoModel, BasicTokenizer, BertTokenizerFast\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import time\n",
    "from layers import LayerNorm\n",
    "import logging\n",
    "from utils import Preprocessor, HandshakingTaggingScheme\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0 will be used\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device {} will be used\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_home = \"/data/yubowen/experiments/relextr/pretrained_model\"\n",
    "project_root = \"/data/yubowen/experiments/relextr\"\n",
    "data_home = os.path.join(project_root, \"data\")\n",
    "\n",
    "experiment_dir = os.path.join(project_root, \"exp\")\n",
    "experiment_name = \"nyt11\"\n",
    "\n",
    "nyt_data_dir = os.path.join(data_home, experiment_name)\n",
    "nyt_train_data_path = os.path.join(nyt_data_dir, \"train_triples.json\")\n",
    "nyt_valid_data_path = os.path.join(nyt_data_dir, \"dev_triples.json\")\n",
    "nyt_test_data_path = os.path.join(nyt_data_dir, \"test_triples.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/wycheng/nyt11\" target=\"_blank\">https://app.wandb.ai/wycheng/nyt11</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/wycheng/nyt11/runs/3in264ld\" target=\"_blank\">https://app.wandb.ai/wycheng/nyt11/runs/3in264ld</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/wycheng/nyt11/runs/3in264ld"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project = experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "config = wandb.config          # Initialize config\n",
    "config.batch_size = 6          # input batch size for training (default: 64)\n",
    "config.test_batch_size = 32    # input batch size for testing (default: 1000)\n",
    "config.epochs = 50             # number of epochs to train (default: 10)\n",
    "config.lr = 5e-5               # learning rate (default: 0.01)\n",
    "config.seed = 2333               # random seed (default: 42)\n",
    "config.log_interval = 10  \n",
    "config.max_seq_len = 100\n",
    "config.sliding_len = 20\n",
    "config.loss_weight_recover_steps = 10000\n",
    "\n",
    "torch.manual_seed(config.seed) # pytorch random seed\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "model_state_dict_dir = wandb.run.dir\n",
    "schedule_state_dict_dir = wandb.run.dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_train_data = json.load(open(nyt_train_data_path, \"r\", encoding = \"utf-8\"))\n",
    "nyt_valid_data = json.load(open(nyt_valid_data_path, \"r\", encoding = \"utf-8\"))\n",
    "nyt_test_data = json.load(open(nyt_test_data_path, \"r\", encoding = \"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bert tokenizer\n",
    "model_path = os.path.join(pretrained_model_home, \"bert-base-cased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path, add_special_tokens = False, do_lower_case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "def get_tok2char_span_map(text):\n",
    "    return tokenizer.encode_plus(text, \n",
    "                               return_offsets_mapping = True, \n",
    "                               add_special_tokens = False)[\"offset_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tran2normal_samples(data):\n",
    "    normal_sample_list = []\n",
    "    for sample in tqdm(data, desc = \"Transforming data format\"):\n",
    "        text = sample[\"text\"]\n",
    "        spo_list = sample[\"triple_list\"]\n",
    "        normal_sample = {\n",
    "            \"text\": text,\n",
    "            \"id\": sample[\"id\"],\n",
    "        }\n",
    "        normal_rel_list = []\n",
    "        for rel in spo_list:\n",
    "            normal_rel_list.append({\n",
    "                \"subject\": rel[0],\n",
    "                \"predicate\": rel[1],\n",
    "                \"object\": rel[2],\n",
    "            })\n",
    "        normal_sample[\"relation_list\"] = normal_rel_list\n",
    "        normal_sample_list.append(normal_sample)\n",
    "    return normal_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62335it [00:00, 206203.44it/s]\n",
      "Transforming data format: 100%|██████████| 62335/62335 [00:02<00:00, 28968.03it/s]\n",
      "Adding token level spans: 100%|██████████| 62335/62335 [00:43<00:00, 1421.93it/s]\n",
      "313it [00:00, 306876.38it/s]\n",
      "Transforming data format: 100%|██████████| 313/313 [00:00<00:00, 140603.74it/s]\n",
      "Adding token level spans: 100%|██████████| 313/313 [00:00<00:00, 1463.31it/s]\n",
      "369it [00:00, 357601.24it/s]\n",
      "Transforming data format: 100%|██████████| 369/369 [00:00<00:00, 178450.15it/s]\n",
      "Adding token level spans: 100%|██████████| 369/369 [00:00<00:00, 1573.62it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(transform_func = tran2normal_samples, \n",
    "                            get_tok2char_span_map_func = get_tok2char_span_map)\n",
    "train_data = preprocessor.get_normal_dataset(nyt_train_data, add_id = True, dataset_name = \"train\")\n",
    "valid_data = preprocessor.get_normal_dataset(nyt_valid_data, add_id = True, dataset_name = \"valid\")\n",
    "test_data = preprocessor.get_normal_dataset(nyt_test_data, add_id = True, dataset_name = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check token level span\n",
    "# def extr_ent(text, tok_span, tok2char_span):\n",
    "#     char_span_list = tok2char_span[tok_span[0]:tok_span[1]]\n",
    "#     char_span = (char_span_list[0][0], char_span_list[-1][1])\n",
    "#     decoded_ent = text[char_span[0]:char_span[1]]\n",
    "#     return decoded_ent\n",
    "\n",
    "# for sample in tqdm(train_data + valid_data + test_data):\n",
    "#     text = sample[\"text\"]\n",
    "#     tok2char_span = get_tok2char_span_map(text)\n",
    "#     for rel in sample[\"relation_list\"]:\n",
    "#         subj_span, obj_span = rel[\"subj_span\"], rel[\"obj_span\"]\n",
    "#         assert extr_ent(text, subj_span, tok2char_span) == rel[\"subject\"] and extr_ent(text, obj_span, tok2char_span) == rel[\"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_short_samples(sample_list, sliding_len = 50):\n",
    "    new_sample_list = []\n",
    "    for sample in tqdm(sample_list, desc = \"Splitting\"):\n",
    "        text_id = sample[\"id\"]\n",
    "        text = sample[\"text\"]\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        offset_map = tokenizer.encode_plus(text, return_offsets_mapping = True, \n",
    "                                           add_special_tokens = False)[\"offset_mapping\"]\n",
    "        \n",
    "        # sliding on token level\n",
    "        split_sample_list = []\n",
    "        for start_ind in range(0, len(tokens), sliding_len):\n",
    "            while \"##\" in tokens[start_ind]:\n",
    "                start_ind -= 1\n",
    "            end_ind = start_ind + config.max_seq_len\n",
    "#             while \"##\" in tokens[end_ind]:\n",
    "#                 end_ind += 1\n",
    "            char_span_list = offset_map[start_ind:end_ind]\n",
    "            char_level_span = (char_span_list[0][0], char_span_list[-1][1])\n",
    "            sub_text = text[char_level_span[0]:char_level_span[1]]\n",
    "\n",
    "            new_sample = {\n",
    "                \"id\": text_id,\n",
    "                \"text\": sub_text,\n",
    "                \"relation_list\": []\n",
    "            }\n",
    "            for rel in sample[\"relation_list\"]:\n",
    "                subj_span = rel[\"subj_span\"]\n",
    "                obj_span = rel[\"obj_span\"]\n",
    "                if subj_span[0] >= start_ind and subj_span[1] <= end_ind \\\n",
    "                    and obj_span[0] >= start_ind and obj_span[1] <= end_ind:\n",
    "                    new_rel = copy.deepcopy(rel)\n",
    "                    new_rel[\"subj_span\"] = (subj_span[0] - start_ind, subj_span[1] - start_ind)\n",
    "                    new_rel[\"obj_span\"] = (obj_span[0] - start_ind, obj_span[1] - start_ind)\n",
    "                    new_sample[\"relation_list\"].append(new_rel)\n",
    "#                 else:\n",
    "#                     set_trace()\n",
    "            if len(new_sample[\"relation_list\"]) > 0:\n",
    "                split_sample_list.append(new_sample)\n",
    "#         if len(split_sample_list) == 0:\n",
    "#             set_trace()\n",
    "        new_sample_list.extend(split_sample_list)\n",
    "    return new_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting: 100%|██████████| 62335/62335 [00:41<00:00, 1495.70it/s]\n",
      "Splitting: 100%|██████████| 313/313 [00:00<00:00, 1519.52it/s]\n",
      "Splitting: 100%|██████████| 369/369 [00:00<00:00, 1602.94it/s]\n"
     ]
    }
   ],
   "source": [
    "short_train_data = split_into_short_samples(train_data, sliding_len = config.sliding_len)\n",
    "short_valid_data = split_into_short_samples(valid_data, sliding_len = config.sliding_len)\n",
    "short_test_data = split_into_short_samples(test_data, sliding_len = config.sliding_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89465 458 552\n"
     ]
    }
   ],
   "source": [
    "print(len(short_train_data), len(short_valid_data), len(short_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63017/63017 [00:00<00:00, 400198.13it/s]\n"
     ]
    }
   ],
   "source": [
    "rel_set = set()\n",
    "for sample in tqdm(train_data + valid_data + test_data):\n",
    "    for rel in sample[\"relation_list\"]:\n",
    "        rel_set.add(rel[\"predicate\"])\n",
    "rel_set = sorted(rel_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id = {rel:ind for ind, rel in enumerate(rel_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "handshaking_tagger = HandshakingTaggingScheme(rel2id = rel2id, max_seq_len = config.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_to(sample1, sample2):\n",
    "    assert sample1[\"id\"] == sample2[\"id\"]\n",
    "    assert sample1[\"text\"] == sample2[\"text\"]\n",
    "    memory_set = set()\n",
    "    for rel in sample2[\"relation_list\"]:\n",
    "        memory = \"{}\\u2E80{}\\u2E80{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], \n",
    "                                                             rel[\"predicate\"], \n",
    "                                                             rel[\"object\"], \n",
    "                                                             str(rel[\"subj_span\"]), \n",
    "                                                             str(rel[\"obj_span\"]))\n",
    "        memory_set.add(memory)\n",
    "    for rel in sample1[\"relation_list\"]:\n",
    "        memory = \"{}\\u2E80{}\\u2E80{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], \n",
    "                                                             rel[\"predicate\"], \n",
    "                                                             rel[\"object\"], \n",
    "                                                             str(rel[\"subj_span\"]), \n",
    "                                                             str(rel[\"obj_span\"]))\n",
    "        if memory not in memory_set:\n",
    "            set_trace()\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_data[1000]\n",
    "# ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = handshaking_tagger.get_spots(sample)\n",
    "\n",
    "# ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag(ent_matrix_spots)\n",
    "# head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(head_rel_matrix_spots)\n",
    "# tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(tail_rel_matrix_spots)\n",
    "# # %timeit spots2shaking_tag(ent_matrix_spots)\n",
    "# text = sample[\"text\"]\n",
    "# tok2char_span_map = get_tok2char_span_map(text)\n",
    "# decoded_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "#                                              ent_shaking_tag, \n",
    "#                                              head_rel_shaking_tag, \n",
    "#                                              tail_rel_shaking_tag, \n",
    "#                                              tok2char_span_map)\n",
    "# # %timeit decode_rel_fr_shaking_tag(text, ent_shaking_tag, head_rel_shaking_tag, tail_rel_shaking_tag, offset_map)\n",
    "# pred_sample = {\n",
    "#     \"id\": sample[\"id\"],\n",
    "#     \"text\": text,\n",
    "#     \"relation_list\": decoded_rel_list,\n",
    "# }\n",
    "# sample_equal_to(pred_sample, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for sample in tqdm(train_data + valid_data + test_data):\n",
    "#     ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = handshaking_tagger.get_spots(sample)\n",
    "\n",
    "#     ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag(ent_matrix_spots)\n",
    "#     head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(head_rel_matrix_spots)\n",
    "#     tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(tail_rel_matrix_spots)\n",
    "#     # %timeit spots2shaking_tag(ent_matrix_spots)\n",
    "#     text = sample[\"text\"]\n",
    "#     tok2char_span_map = get_tok2char_span_map(text)\n",
    "#     decoded_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "#                                                  ent_shaking_tag, \n",
    "#                                                  head_rel_shaking_tag, \n",
    "#                                                  tail_rel_shaking_tag, \n",
    "#                                                  tok2char_span_map)\n",
    "#     # %timeit decode_rel_fr_shaking_tag(text, ent_shaking_tag, head_rel_shaking_tag, tail_rel_shaking_tag, offset_map)\n",
    "#     pred_sample = {\n",
    "#         \"id\": sample[\"id\"],\n",
    "#         \"text\": text,\n",
    "#         \"relation_list\": decoded_rel_list,\n",
    "#     }\n",
    "#     if not sample_equal_to(pred_sample, sample) or not sample_equal_to(pred_sample, sample):\n",
    "# #         set_trace()\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check batch tagging and decoding\n",
    "# batch_samples = train_data[:100]\n",
    "# batch_ent_spots, batch_head_rel_spots, batch_tail_rel_spots = [], [], []\n",
    "# for sample in tqdm(batch_samples):\n",
    "#     ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = handshaking_tagger.get_spots(sample)\n",
    "#     batch_ent_spots.append(ent_matrix_spots)\n",
    "#     batch_head_rel_spots.append(head_rel_matrix_spots)\n",
    "#     batch_tail_rel_spots.append(tail_rel_matrix_spots)\n",
    "# batch_ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag4batch(batch_ent_spots)\n",
    "# batch_head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(batch_head_rel_spots)\n",
    "# batch_tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(batch_tail_rel_spots)\n",
    "\n",
    "# for ind, sample in tqdm(enumerate(batch_samples)):\n",
    "#     text = sample[\"text\"]\n",
    "#     tok2char_span = get_tok2char_span_map(text)\n",
    "#     ent_shaking_tag = batch_ent_shaking_tag[ind]\n",
    "#     head_rel_shaking_tag = batch_head_rel_shaking_tag[ind]\n",
    "#     tail_rel_shaking_tag = batch_tail_rel_shaking_tag[ind]\n",
    "#     decoded_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "#                                                                      ent_shaking_tag,\n",
    "#                                                                      head_rel_shaking_tag,\n",
    "#                                                                      tail_rel_shaking_tag,\n",
    "#                                                                      tok2char_span)\n",
    "#     pred_sample = {\n",
    "#         \"id\": sample[\"id\"],\n",
    "#         \"text\": text,\n",
    "#         \"relation_list\": decoded_rel_list,\n",
    "#     }\n",
    "#     if not sample_equal_to(pred_sample, sample):\n",
    "#         set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "def get_indexed_train_valid_data(data):\n",
    "    indexed_samples = []\n",
    "    for ind, sample in tqdm(enumerate(data), desc = \"Generate indexed train or valid data\"):\n",
    "        text = sample[\"text\"]\n",
    "        text_id = sample[\"id\"]\n",
    "        # codes for bert input\n",
    "        # @specific\n",
    "        codes = tokenizer.encode_plus(text, \n",
    "                                    return_offsets_mapping = True, \n",
    "                                    add_special_tokens = False,\n",
    "                                    max_length = config.max_seq_len, \n",
    "                                    pad_to_max_length = True)\n",
    "        \n",
    "        \n",
    "        # tagging\n",
    "        spots_tuple = handshaking_tagger.get_spots(sample)\n",
    "        \n",
    "        # get codes\n",
    "        # @specific\n",
    "        input_ids = torch.tensor(codes[\"input_ids\"]).long()\n",
    "        attention_mask = torch.tensor(codes[\"attention_mask\"]).long()\n",
    "        token_type_ids = torch.tensor(codes[\"token_type_ids\"]).long()\n",
    "        offset_map = codes[\"offset_mapping\"]\n",
    "\n",
    "        sample_tp = (text_id,\n",
    "                     text, \n",
    "                     input_ids,\n",
    "                     attention_mask,\n",
    "                     token_type_ids,\n",
    "                     offset_map,\n",
    "                     spots_tuple,\n",
    "                    )\n",
    "        indexed_samples.append(sample_tp)       \n",
    "    return indexed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "def get_indexed_pred_data(data):\n",
    "    indexed_samples = []\n",
    "    for ind, sample in tqdm(enumerate(data), desc = \"Generate indexed pred data\"):\n",
    "        text = sample[\"text\"] \n",
    "        text_id = sample[\"id\"]\n",
    "        # @specific\n",
    "        codes = tokenizer.encode_plus(text, \n",
    "                                    return_offsets_mapping = True, \n",
    "                                    add_special_tokens = False,\n",
    "                                    max_length = config.max_seq_len, \n",
    "                                    pad_to_max_length = True)\n",
    "        \n",
    "        input_ids = torch.tensor(codes[\"input_ids\"]).long()\n",
    "        attention_mask = torch.tensor(codes[\"attention_mask\"]).long()\n",
    "        token_type_ids = torch.tensor(codes[\"token_type_ids\"]).long()\n",
    "        offset_map = codes[\"offset_mapping\"]\n",
    "\n",
    "        sample_tp = (text_id,\n",
    "                     text, \n",
    "                     input_ids,\n",
    "                     attention_mask,\n",
    "                     token_type_ids,\n",
    "                     offset_map,\n",
    "                     )\n",
    "        indexed_samples.append(sample_tp)       \n",
    "    return indexed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_dev_batch(batch_data):\n",
    "    text_id_list = []\n",
    "    text_list = []\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    token_type_ids_list = [] \n",
    "    offset_map_list = []\n",
    "    ent_spots_list = []\n",
    "    head_rel_spots_list = []\n",
    "    tail_rel_spots_list = []\n",
    "    \n",
    "    for sample in batch_data:\n",
    "        text_id_list.append(sample[0])\n",
    "        text_list.append(sample[1])\n",
    "        input_ids_list.append(sample[2])\n",
    "        attention_mask_list.append(sample[3])        \n",
    "        token_type_ids_list.append(sample[4])        \n",
    "        offset_map_list.append(sample[5])\n",
    "        \n",
    "        ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = sample[6]\n",
    "        ent_spots_list.append(ent_matrix_spots)\n",
    "        head_rel_spots_list.append(head_rel_matrix_spots)\n",
    "        tail_rel_spots_list.append(tail_rel_matrix_spots)\n",
    "    \n",
    "    # @specific: codes indexed by bert tokenizer\n",
    "    batch_input_ids = torch.stack(input_ids_list, dim = 0)\n",
    "    batch_attention_mask = torch.stack(attention_mask_list, dim = 0)\n",
    "    batch_token_type_ids = torch.stack(token_type_ids_list, dim = 0)\n",
    "    \n",
    "#     t1 = time.time()\n",
    "    batch_ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag4batch(ent_spots_list)\n",
    "    batch_head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(head_rel_spots_list)\n",
    "    batch_tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(tail_rel_spots_list)\n",
    "#     print(time.time() - t1)\n",
    "    return text_id_list, text_list, batch_input_ids, batch_attention_mask, batch_token_type_ids, offset_map_list, batch_ent_shaking_tag, batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pred_batch(batch_data):\n",
    "    text_ids = []\n",
    "    text_list = []\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    token_type_ids = [] \n",
    "    offset_map = []\n",
    "    for sample in batch_data:\n",
    "        text_ids.append(sample[0])\n",
    "        text_list.append(sample[1])\n",
    "        input_ids.append(sample[2])\n",
    "        attention_mask.append(sample[3])        \n",
    "        token_type_ids.append(sample[4])        \n",
    "        offset_map.append(sample[5])\n",
    "    input_ids = torch.stack(input_ids, dim = 0)\n",
    "    attention_mask = torch.stack(attention_mask, dim = 0)\n",
    "    token_type_ids = torch.stack(token_type_ids, dim = 0)\n",
    "    return text_ids, text_list, input_ids, attention_mask, token_type_ids, offset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @uni\n",
    "def get_train_dev_dataloader_gen(indexed_train_sample_list, indexed_dev_sample_list, batch_size):\n",
    "    train_dataloader = DataLoader(MyDataset(indexed_train_sample_list), \n",
    "                                      batch_size = batch_size, \n",
    "                                      shuffle = True, \n",
    "                                      num_workers = 6,\n",
    "                                      drop_last = False,\n",
    "                                      collate_fn = generate_train_dev_batch,\n",
    "                                     )\n",
    "    dev_dataloader = DataLoader(MyDataset(indexed_dev_sample_list), \n",
    "                              batch_size = batch_size, \n",
    "                              shuffle = True, \n",
    "                              num_workers = 6,\n",
    "                              drop_last = False,\n",
    "                              collate_fn = generate_train_dev_batch,\n",
    "                             )\n",
    "    return train_dataloader, dev_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 89465it [00:55, 1617.43it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_train_data = get_indexed_train_valid_data(short_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 458it [00:00, 1565.99it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_valid_data = get_indexed_train_valid_data(short_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at dataloader\n",
    "train_dataloader, dev_dataloader = get_train_dev_dataloader_gen(indexed_train_data, indexed_valid_data, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test data loading time\n",
    "\n",
    "# # 0 workers: 40, 41\n",
    "# # 3 workers: 28\n",
    "# # 4 workers: 23\n",
    "# # 5 workers: 19\n",
    "# # 6 workers: 16, \n",
    "# # 7 workers: 22, 28, 21\n",
    "# # 10 wokers: 27, 28, \n",
    "# for ep in range(100):\n",
    "#     t1 = time.time()\n",
    "#     for ind, batch_data in enumerate(dev_dataloader):\n",
    "#         print(\"\\r{}/{}\".format(ind + 1, len(dev_dataloader)), end = \"\")\n",
    "#     print(\"ep {}: {}\".format(ep + 1, time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_iter = iter(train_dataloader)\n",
    "# %timeit next(train_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gov. Mark Warner , Democrat of Virginia ; Senator Russell D. Feingold , Democrat of Wisconsin ; and Senator Bill Frist , Republican of Tennessee . ''\n",
      "\n",
      "Gov. Mark Warner, Democrat of Virginia ; Senator Russell D. Feingold, Democrat of Wisconsin ; and Senator Bill Frist, Republican of Tennessee.'' [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "torch.Size([32, 100])\n",
      "32\n",
      "torch.Size([32, 5050])\n",
      "torch.Size([32, 12, 5050])\n",
      "torch.Size([32, 12, 5050])\n"
     ]
    }
   ],
   "source": [
    "train_data_iter = iter(train_dataloader)\n",
    "batch_data = next(train_data_iter)\n",
    "text_id_list, text_list, batch_input_ids, \\\n",
    "batch_attention_mask, batch_token_type_ids, \\\n",
    "offset_map_list, batch_ent_shaking_tag, \\\n",
    "batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_data\n",
    "\n",
    "print(text_list[0])\n",
    "print()\n",
    "print(tokenizer.decode(batch_input_ids[0].tolist()))\n",
    "print(batch_input_ids.size())\n",
    "print(batch_attention_mask.size())\n",
    "print(batch_token_type_ids.size())\n",
    "print(len(offset_map_list))\n",
    "print(batch_ent_shaking_tag.size())\n",
    "print(batch_head_rel_shaking_tag.size())\n",
    "print(batch_tail_rel_shaking_tag.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelExtractor(nn.Module):\n",
    "    def __init__(self, encoder, rel_size):\n",
    "        super().__init__()\n",
    "        # @specific\n",
    "        self.encoder = encoder\n",
    "        hidden_size = encoder.config.hidden_size\n",
    "\n",
    "        self.ent_fc = nn.Linear(hidden_size, 2)\n",
    "        self.head_rel_fc_list = [nn.Linear(hidden_size, 3) for _ in range(rel_size)]\n",
    "        self.tail_rel_fc_list = [nn.Linear(hidden_size, 3) for _ in range(rel_size)]\n",
    "        \n",
    "        # register fcs\n",
    "#         for ind, fc in enumerate(self.ent_fc_list):\n",
    "#             self.register_parameter(\"weight_4_ent_in_rel{}\".format(ind), fc.weight)\n",
    "#             self.register_parameter(\"bias_4_ent_in_rel{}\".format(ind), fc.bias)\n",
    "        for ind, fc in enumerate(self.head_rel_fc_list):\n",
    "            self.register_parameter(\"weight_4_head_rel{}\".format(ind), fc.weight)\n",
    "            self.register_parameter(\"bias_4_head_rel{}\".format(ind), fc.bias)\n",
    "        for ind, fc in enumerate(self.tail_rel_fc_list):\n",
    "            self.register_parameter(\"weight_4_tail_rel{}\".format(ind), fc.weight)\n",
    "            self.register_parameter(\"bias_4_tail_rel{}\".format(ind), fc.bias)\n",
    "            \n",
    "        # conditional layer normaliztion\n",
    "        fake_inputs = torch.zeros([config.batch_size, config.max_seq_len, hidden_size])\n",
    "        self.cond_layer_norm = LayerNorm(fake_inputs.size(), hidden_size, conditional = True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # @specific\n",
    "        # input_ids, attention_mask, token_type_ids: (batch_size, seq_len)\n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "        # last_hidden_state: (batch_size, seq_len, hidden_size)\n",
    "        last_hidden_state = context_outputs[0]\n",
    "        \n",
    "        # shaking_hiddens: (batch_size, 1 + ... + seq_len, hidden_size)\n",
    "        shaking_hiddens = self.shake_hands_afterwards(last_hidden_state)\n",
    "        \n",
    "        ent_shaking_outputs = self.ent_fc(shaking_hiddens)\n",
    "            \n",
    "        head_rel_shaking_outputs_list = []\n",
    "        for fc in self.head_rel_fc_list:\n",
    "            head_rel_shaking_outputs_list.append(fc(shaking_hiddens))\n",
    "            \n",
    "        tail_rel_shaking_outputs_list = []\n",
    "        for fc in self.tail_rel_fc_list:\n",
    "            tail_rel_shaking_outputs_list.append(fc(shaking_hiddens))\n",
    "        \n",
    "        head_rel_shaking_outputs = torch.stack(head_rel_shaking_outputs_list, dim = 1)\n",
    "        tail_rel_shaking_outputs = torch.stack(tail_rel_shaking_outputs_list, dim = 1)\n",
    "        \n",
    "        return ent_shaking_outputs, head_rel_shaking_outputs, tail_rel_shaking_outputs\n",
    "\n",
    "    def shake_hands_afterwards(self, seq_hiddens):\n",
    "        '''\n",
    "        seq_hiddens: (batch_size, seq_len, hidden_size) (32, 3, 5)\n",
    "        return shake_hands_matrix_hiddens: (batch_size, (1 + seq_len) * seq_len / 2, hidden_size) (32, 5+4+3+2+1, 5)\n",
    "        '''\n",
    "        seq_len = seq_hiddens.size()[-2]\n",
    "        shake_hands_hidden_list = []\n",
    "        for ind in range(seq_len):\n",
    "            hidden_each_step = seq_hiddens[:, ind, :]\n",
    "            # seq_len - ind: only shake afterwards\n",
    "            repeat_hidden_each_step = hidden_each_step[:, None, :].repeat(1, seq_len - ind, 1) \n",
    "    #         shake_hands_hidden = torch.cat([repeat_hidden_each_step, seq_hiddens[:, ind:, :]], dim = -1)\n",
    "            shake_hands_hidden = self.cond_layer_norm(seq_hiddens[:, ind:, :], repeat_hidden_each_step)\n",
    "            shake_hands_hidden_list.append(shake_hands_hidden)\n",
    "        shake_hands_matrix_hiddens = torch.cat(shake_hands_hidden_list, dim = 1)\n",
    "        return shake_hands_matrix_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = AutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extractor = RelExtractor(roberta, len(rel2id))\n",
    "rel_extractor = rel_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.watch(rel_extractor, log = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test model\n",
    "# batch_input_ids, \\\n",
    "# batch_attention_mask,\\\n",
    "# batch_token_type_ids = batch_input_ids.to(device), \\\n",
    "#                          batch_attention_mask.to(device), \\\n",
    "#                          batch_token_type_ids.to(device)\n",
    "# with torch.no_grad():                 \n",
    "#     ent_shaking_outputs, \\\n",
    "#     head_rel_shaking_outputs, \\\n",
    "#     tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "#                                               batch_attention_mask, \n",
    "#                                               batch_token_type_ids)\n",
    "\n",
    "# print(ent_shaking_outputs.size())\n",
    "# print(head_rel_shaking_outputs.size())\n",
    "# print(tail_rel_shaking_outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_loss(weights = None):\n",
    "    if weights is not None:\n",
    "        weights = torch.FloatTensor(weights).to(device)\n",
    "    cross_en = nn.CrossEntropyLoss(weight = weights)  \n",
    "    return lambda pred, target: cross_en(pred.view(-1, pred.size()[-1]), target.view(-1))\n",
    "loss_func = bias_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_accuracy(pred, truth):\n",
    "    '''\n",
    "    计算所有抽取字段都正确的样本比例\n",
    "    即该batch的输出与truth全等的样本比例\n",
    "    '''\n",
    "    # (batch_size, ..., seq_len, tag_size) -> (batch_size, ..., seq_len)\n",
    "    pred_id = torch.argmax(pred, dim = -1)\n",
    "    # (batch_size, ..., seq_len) -> (batch_size, )，把每个sample压成一条seq\n",
    "    pred_id = pred_id.view(pred_id.size()[0], -1)\n",
    "    truth = truth.view(truth.size()[0], -1)\n",
    "    \n",
    "    # (batch_size, )，每个元素是pred与truth之间tag相同的数量\n",
    "    correct_tag_num = torch.sum(torch.eq(truth, pred_id).float(), dim = 1)\n",
    "\n",
    "    # seq维上所有tag必须正确，所以correct_tag_num必须等于seq的长度才算一个correct的sample\n",
    "    sample_acc_ = torch.eq(correct_tag_num, torch.ones_like(correct_tag_num) * truth.size()[-1]).float()\n",
    "    sample_acc = torch.mean(sample_acc_)\n",
    "    \n",
    "    return sample_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_cpg(text_list, offset_map_list, \n",
    "                 batch_pred_ent_shaking_outputs,\n",
    "                 batch_pred_head_rel_shaking_outputs,\n",
    "                 batch_pred_tail_rel_shaking_outputs,\n",
    "                 batch_gold_ent_shaking_tag,\n",
    "                 batch_gold_head_rel_shaking_tag,\n",
    "                 batch_gold_tail_rel_shaking_tag):\n",
    "    batch_pred_ent_shaking_tag = torch.argmax(batch_pred_ent_shaking_outputs, dim = -1)\n",
    "    batch_pred_head_rel_shaking_tag = torch.argmax(batch_pred_head_rel_shaking_outputs, dim = -1)\n",
    "    batch_pred_tail_rel_shaking_tag = torch.argmax(batch_pred_tail_rel_shaking_outputs, dim = -1)\n",
    "    \n",
    "    correct_num, pred_num, gold_num = 0, 0, 0\n",
    "    for ind in range(len(text_list)):\n",
    "        text = text_list[ind]\n",
    "        offset_map = offset_map_list[ind]\n",
    "        gold_ent_shaking_tag, pred_ent_shaking_tag = batch_gold_ent_shaking_tag[ind], batch_pred_ent_shaking_tag[ind]\n",
    "        gold_head_rel_shaking_tag, pred_head_rel_shaking_tag = batch_gold_head_rel_shaking_tag[ind], batch_pred_head_rel_shaking_tag[ind]\n",
    "        gold_tail_rel_shaking_tag, pred_tail_rel_shaking_tag = batch_gold_tail_rel_shaking_tag[ind], batch_pred_tail_rel_shaking_tag[ind]\n",
    "        \n",
    "        pred_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "                                                  pred_ent_shaking_tag, \n",
    "                                                  pred_head_rel_shaking_tag, \n",
    "                                                  pred_tail_rel_shaking_tag, \n",
    "                                                  offset_map)\n",
    "        gold_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "                                                  gold_ent_shaking_tag, \n",
    "                                                  gold_head_rel_shaking_tag, \n",
    "                                                  gold_tail_rel_shaking_tag, \n",
    "                                                  offset_map)\n",
    "\n",
    "        gold_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in gold_rel_list])\n",
    "        pred_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in pred_rel_list])\n",
    "        \n",
    "        for rel_str in pred_rel_set:\n",
    "            if rel_str in gold_rel_set:\n",
    "                correct_num += 1\n",
    "        \n",
    "        pred_num += len(gold_rel_set)\n",
    "        gold_num += len(pred_rel_set)\n",
    "        \n",
    "    return correct_num, pred_num, gold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(correct_num, pred_num, gold_num):\n",
    "    minimini = 1e-10\n",
    "    precision = correct_num / (pred_num + minimini)\n",
    "    recall = correct_num / (gold_num + minimini)\n",
    "    f1 = 2 * precision * recall / (precision + recall + minimini)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train step\n",
    "def train_step(batch_train_data, optimizer, loss_weights):\n",
    "    text_id_list, text_list, batch_input_ids, \\\n",
    "    batch_attention_mask, batch_token_type_ids, \\\n",
    "    offset_map_list, batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_train_data\n",
    "    \n",
    "    batch_input_ids, \\\n",
    "    batch_attention_mask, \\\n",
    "    batch_token_type_ids, \\\n",
    "    batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, \\\n",
    "    batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                              batch_attention_mask.to(device), \n",
    "                              batch_token_type_ids.to(device), \n",
    "                              batch_ent_shaking_tag.to(device), \n",
    "                              batch_head_rel_shaking_tag.to(device), \n",
    "                              batch_tail_rel_shaking_tag.to(device)\n",
    "                             )\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    ent_shaking_outputs, \\\n",
    "    head_rel_shaking_outputs, \\\n",
    "    tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                              batch_attention_mask, \n",
    "                                              batch_token_type_ids, \n",
    "                                             )\n",
    "\n",
    "    w_ent, w_rel = loss_weights[\"ent\"], loss_weights[\"rel\"]\n",
    "    loss = w_ent * loss_func(ent_shaking_outputs, batch_ent_shaking_tag) + \\\n",
    "            w_rel * loss_func(head_rel_shaking_outputs, batch_head_rel_shaking_tag) + \\\n",
    "            w_rel * loss_func(tail_rel_shaking_outputs, batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    # bp time: 2s\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    ent_sample_acc = get_sample_accuracy(ent_shaking_outputs, \n",
    "                                          batch_ent_shaking_tag)\n",
    "    head_rel_sample_acc = get_sample_accuracy(head_rel_shaking_outputs, \n",
    "                                             batch_head_rel_shaking_tag)\n",
    "    tail_rel_sample_acc = get_sample_accuracy(tail_rel_shaking_outputs, \n",
    "                                             batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    return loss.item(), ent_sample_acc.item(), head_rel_sample_acc.item(), tail_rel_sample_acc.item()\n",
    "\n",
    "# valid step\n",
    "def valid_step(batch_valid_data):\n",
    "    text_id_list, text_list, batch_input_ids, \\\n",
    "    batch_attention_mask, batch_token_type_ids, \\\n",
    "    offset_map_list, batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_valid_data\n",
    "    \n",
    "    batch_input_ids, \\\n",
    "    batch_attention_mask, \\\n",
    "    batch_token_type_ids, \\\n",
    "    batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, \\\n",
    "    batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                              batch_attention_mask.to(device), \n",
    "                              batch_token_type_ids.to(device), \n",
    "                              batch_ent_shaking_tag.to(device), \n",
    "                              batch_head_rel_shaking_tag.to(device), \n",
    "                              batch_tail_rel_shaking_tag.to(device)\n",
    "                             )\n",
    "    with torch.no_grad():\n",
    "        ent_shaking_outputs, \\\n",
    "        head_rel_shaking_outputs, \\\n",
    "        tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                                  batch_attention_mask, \n",
    "                                                  batch_token_type_ids, \n",
    "                                                 )\n",
    "    \n",
    "    ent_sample_acc = get_sample_accuracy(ent_shaking_outputs, \n",
    "                                          batch_ent_shaking_tag)\n",
    "    head_rel_sample_acc = get_sample_accuracy(head_rel_shaking_outputs, \n",
    "                                             batch_head_rel_shaking_tag)\n",
    "    tail_rel_sample_acc = get_sample_accuracy(tail_rel_shaking_outputs, \n",
    "                                             batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    rel_cpg = get_rel_cpg(text_list, offset_map_list, \n",
    "                            ent_shaking_outputs,\n",
    "                            head_rel_shaking_outputs,\n",
    "                            tail_rel_shaking_outputs,\n",
    "                            batch_ent_shaking_tag,\n",
    "                            batch_head_rel_shaking_tag,\n",
    "                            batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    return ent_sample_acc.item(), head_rel_sample_acc.item(), tail_rel_sample_acc.item(), rel_cpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = 0.\n",
    "def train_n_valid(train_dataloader, dev_dataloader, optimizer, scheduler, num_epoch):  \n",
    "    def train(dataloader, ep):\n",
    "        # train\n",
    "        rel_extractor.train()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        start_lr = optimizer.param_groups[0]['lr']\n",
    "        total_loss, total_ent_sample_acc, total_head_rel_sample_acc, total_tail_rel_sample_acc = 0., 0., 0., 0.\n",
    "        for batch_ind, batch_train_data in enumerate(dataloader):\n",
    "            t_batch = time.time()\n",
    "            z = (2 * len(rel2id) + 1)\n",
    "            steps_per_ep = len(dataloader)\n",
    "            total_steps = config.loss_weight_recover_steps\n",
    "            current_step = steps_per_ep * ep + batch_ind\n",
    "            w_ent = max(1 / z + 1 - current_step / total_steps, 1 / z)\n",
    "            w_rel = min((len(rel2id) / z) * current_step / total_steps, (len(rel2id) / z))\n",
    "            loss, ent_sample_acc, head_rel_sample_acc, tail_rel_sample_acc = train_step(batch_train_data, optimizer, loss_weights)\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_ent_sample_acc += ent_sample_acc\n",
    "            total_head_rel_sample_acc += head_rel_sample_acc\n",
    "            total_tail_rel_sample_acc += tail_rel_sample_acc\n",
    "            \n",
    "            avg_loss = total_loss / (batch_ind + 1)\n",
    "            avg_ent_sample_acc = total_ent_sample_acc / (batch_ind + 1)\n",
    "            avg_head_rel_sample_acc = total_head_rel_sample_acc / (batch_ind + 1)\n",
    "            avg_tail_rel_sample_acc = total_tail_rel_sample_acc / (batch_ind + 1)\n",
    "            \n",
    "            batch_print_format = \"\\rEpoch: {}/{}, batch: {}/{}, train_loss: {}, \" + \\\n",
    "                                \"t_ent_sample_acc: {}, t_head_rel_sample_acc: {}, t_tail_rel_sample_acc: {},\" + \\\n",
    "                                 \"lr: {}, batch_time: {}, total_time: {} -------------\"\n",
    "                    \n",
    "            print(batch_print_format.format(ep + 1, num_epoch, \n",
    "                                            batch_ind + 1, len(dataloader), \n",
    "                                            avg_loss, \n",
    "                                            avg_ent_sample_acc,\n",
    "                                            avg_head_rel_sample_acc,\n",
    "                                            avg_tail_rel_sample_acc,\n",
    "                                            optimizer.param_groups[0]['lr'],\n",
    "                                            time.time() - t_batch,\n",
    "                                            time.time() - t_ep,\n",
    "                                           ), end=\"\")\n",
    "            \n",
    "            if batch_ind % config.log_interval == 0:\n",
    "                wandb.log({\n",
    "                    \"train_loss\": avg_loss,\n",
    "                    \"train_ent_seq_acc\": avg_ent_sample_acc,\n",
    "                    \"train_head_rel_acc\": avg_head_rel_sample_acc,\n",
    "                    \"train_tail_rel_acc\": avg_tail_rel_sample_acc,\n",
    "                    \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "                    \"time\": time.time() - t_ep,\n",
    "                })\n",
    "            \n",
    "#         log_format = \"Epoch: {}/{}, train_sample_acc(ent, head_rel, tail_rel): ({},{},{}), start_lr:{}, end_lr: {}, ep_time: {}\"\n",
    "#         logger.info(log_format.format(ep + 1, num_epoch, \n",
    "#                                       avg_ent_sample_acc, \n",
    "#                                       avg_head_rel_sample_acc, \n",
    "#                                       avg_tail_rel_sample_acc, \n",
    "#                                       start_lr, \n",
    "#                                       optimizer.param_groups[0]['lr'], \n",
    "#                                       time.time() - t_ep))\n",
    "        \n",
    "    def valid(dataloader, ep):\n",
    "        # valid\n",
    "        rel_extractor.eval()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        total_ent_sample_acc, total_head_rel_sample_acc, total_tail_rel_sample_acc = 0., 0., 0.\n",
    "        total_rel_correct_num, total_rel_pred_num, total_rel_gold_num = 0, 0, 0\n",
    "        for batch_ind, batch_valid_data in enumerate(tqdm(dataloader, desc = \"Validating\")):\n",
    "            ent_sample_acc, head_rel_sample_acc, tail_rel_sample_acc, rel_cpg = valid_step(batch_valid_data)\n",
    "\n",
    "            total_ent_sample_acc += ent_sample_acc\n",
    "            total_head_rel_sample_acc += head_rel_sample_acc\n",
    "            total_tail_rel_sample_acc += tail_rel_sample_acc\n",
    "            \n",
    "            total_rel_correct_num += rel_cpg[0]\n",
    "            total_rel_pred_num += rel_cpg[1]\n",
    "            total_rel_gold_num += rel_cpg[2]\n",
    "\n",
    "        avg_ent_sample_acc = total_ent_sample_acc / len(dataloader)\n",
    "        avg_head_rel_sample_acc = total_head_rel_sample_acc / len(dataloader)\n",
    "        avg_tail_rel_sample_acc = total_tail_rel_sample_acc / len(dataloader)\n",
    "        \n",
    "        rel_prf = get_scores(total_rel_correct_num, total_rel_pred_num, total_rel_gold_num)\n",
    "        \n",
    "        log_dict = {\n",
    "                        \"val_ent_seq_acc\": avg_ent_sample_acc,\n",
    "                        \"val_head_rel_acc\": avg_head_rel_sample_acc,\n",
    "                        \"val_tail_rel_acc\": avg_tail_rel_sample_acc,\n",
    "                        \"val_prec\": rel_prf[0],\n",
    "                        \"val_recall\": rel_prf[1],\n",
    "                        \"val_f1\": rel_prf[2],\n",
    "                        \"time\": time.time() - t_ep,\n",
    "                    }\n",
    "        wandb.log(log_dict)\n",
    "        pprint(log_dict)\n",
    "        \n",
    "        return rel_prf[2]\n",
    "        \n",
    "    for ep in range(num_epoch):\n",
    "        train(train_dataloader, ep)   \n",
    "        valid_f1 = valid(dev_dataloader, ep)\n",
    "        \n",
    "        global max_f1\n",
    "        if valid_f1 >= max_f1: \n",
    "            max_f1 = valid_f1\n",
    "            if valid_f1 > 0.5: # save the best model\n",
    "                modle_state_num = len(glob.glob(model_state_dict_dir + \"/model_state_dict_*.pt\"))\n",
    "                torch.save(rel_extractor.state_dict(), os.path.join(model_state_dict_dir, \"model_state_dict_{}.pt\".format(modle_state_num)))\n",
    "                scheduler_state_num = len(glob.glob(schedule_state_dict_dir + \"/scheduler_state_dict_*.pt\"))\n",
    "                torch.save(scheduler.state_dict(), os.path.join(schedule_state_dict_dir, \"scheduler_state_dict_{}.pt\".format(scheduler_state_num))) \n",
    "        print(\"Current avf_f1: {}, Best f1: {}\".format(valid_f1, max_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rel_extractor.state_dict(), os.path.join(model_state_dict_dir, \"model_state_dict_{}.pt\".format(0))) \n",
    "# torch.save(scheduler.state_dict(), os.path.join(schedule_state_dict_dir, \"scheduler_state_dict_{}.pt\".format(0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_state_path(state_dir, pre_fix):\n",
    "    max_file_num = -1\n",
    "    last_state_path = None\n",
    "    for path in glob.glob(state_dir + \"/{}_*.pt\".format(pre_fix)):\n",
    "        file_num = re.search(\"state_dict_(\\d+)\\.pt\", path).group(1)\n",
    "        if int(file_num) > max_file_num:\n",
    "            max_file_num = int(file_num)\n",
    "            last_state_path = path\n",
    "    return last_state_path\n",
    "\n",
    "def get_model_state_path(state_dict_dir, state_dict_num):\n",
    "    return os.path.join(state_dict_dir, \"model_state_dict_{}.pt\".format(state_dict_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "print(\"preparing dataloader...\")\n",
    "train_dataloader, \\\n",
    "dev_dataloader = get_train_dev_dataloader_gen(indexed_train_data, \n",
    "                                            indexed_valid_data, \n",
    "                                            config.batch_size, \n",
    "                                            )\n",
    "print(\"dataloaders done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "init_learning_rate = config.lr\n",
    "optimizer = torch.optim.Adam(rel_extractor.parameters(), lr = init_learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, len(train_dataloader) * 2)\n",
    "\n",
    "# decay_rate = 0.99\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch_num = config.epochs\n",
    "# load the last best state (if any)\n",
    "model_last_state_path = get_last_state_path(model_state_dict_dir, \"model_state_dict\")\n",
    "if model_last_state_path is not None:\n",
    "    rel_extractor.load_state_dict(torch.load(model_last_state_path))\n",
    "    print(\"------------model state {} loaded ----------------\".format(model_last_state_path.split(\"/\")[-1]))\n",
    "    \n",
    "scheduler_last_state_path = get_last_state_path(schedule_state_dict_dir, \"scheduler_state_dict\")  \n",
    "if scheduler_last_state_path is not None:\n",
    "    scheduler.load_state_dict(torch.load(scheduler_last_state_path))\n",
    "    print(\"------------scheduler state {} loaded ----------------\".format(scheduler_last_state_path.split(\"/\")[-1]))\n",
    "\n",
    "train_n_valid(train_dataloader, dev_dataloader, optimizer, scheduler, epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict_dir = os.path.join(project_root, \"notebook/wandb/run-20200529_153219-3nj0nz8n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------model state model_state_dict_8.pt loaded ----------------\n"
     ]
    }
   ],
   "source": [
    "model_state_path = get_last_state_path(model_state_dict_dir, \"model_state_dict\")\n",
    "# model_state_path = get_model_state_path(model_state_dict_dir, 16)\n",
    "rel_extractor.load_state_dict(torch.load(model_state_path))\n",
    "rel_extractor.eval()\n",
    "print(\"------------model state {} loaded ----------------\".format(model_state_path.split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_duplicates(rel_list):\n",
    "    rel_memory_set = set()\n",
    "    filtered_rel_list = []\n",
    "    for rel in rel_list:\n",
    "        rel_memory = \"{}\\u2E80\\{}\\u2E80\\{}\\u2E80\\{}\\u2E80{}\".format(*rel.values())\n",
    "        if rel_memory not in rel_memory_set:\n",
    "            filtered_rel_list.append(rel)\n",
    "            rel_memory_set.add(rel_memory)\n",
    "    return filtered_rel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(short_test_data):\n",
    "    '''\n",
    "    short_test_data: seq_len <= max_seq_len\n",
    "    '''\n",
    "    indexed_test_data = get_indexed_train_valid_data(short_test_data)\n",
    "    test_dataloader = DataLoader(MyDataset(indexed_test_data), \n",
    "                              batch_size = config.test_batch_size, \n",
    "                              shuffle = False, \n",
    "                              num_workers = 0,\n",
    "                              drop_last = False,\n",
    "                              collate_fn = generate_pred_batch,\n",
    "                             )\n",
    "    short_pred_sample_list = []\n",
    "    for batch_test_data in tqdm(test_dataloader, desc = \"Predicting\"):\n",
    "        text_id_list, text_list, batch_input_ids, \\\n",
    "        batch_attention_mask, batch_token_type_ids, \\\n",
    "        offset_map_list = batch_test_data\n",
    "\n",
    "        batch_input_ids, \\\n",
    "        batch_attention_mask, \\\n",
    "        batch_token_type_ids = (batch_input_ids.to(device), \n",
    "                                  batch_attention_mask.to(device), \n",
    "                                  batch_token_type_ids.to(device)\n",
    "                                 )\n",
    "        with torch.no_grad():\n",
    "            batch_ent_shaking_outputs, \\\n",
    "            batch_head_rel_shaking_outputs, \\\n",
    "            batch_tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                                              batch_attention_mask, \n",
    "                                                              batch_token_type_ids, \n",
    "                                                             )\n",
    "\n",
    "        batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, \\\n",
    "        batch_tail_rel_shaking_tag = torch.argmax(batch_ent_shaking_outputs, dim = -1), \\\n",
    "                                     torch.argmax(batch_head_rel_shaking_outputs, dim = -1), \\\n",
    "                                     torch.argmax(batch_tail_rel_shaking_outputs, dim = -1)\n",
    "\n",
    "        for ind in range(len(text_list)):\n",
    "            text, offset_map = text_list[ind], offset_map_list[ind]\n",
    "            ent_shaking_tag, \\\n",
    "            head_rel_shaking_tag, \\\n",
    "            tail_rel_shaking_tag = batch_ent_shaking_tag[ind], \\\n",
    "                                    batch_head_rel_shaking_tag[ind], \\\n",
    "                                    batch_tail_rel_shaking_tag[ind]\n",
    "            rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "                                                  ent_shaking_tag, \n",
    "                                                  head_rel_shaking_tag, \n",
    "                                                  tail_rel_shaking_tag, \n",
    "                                                  offset_map)\n",
    "            short_pred_sample_list.append({\n",
    "                \"text\": text,\n",
    "                \"id\": text_id_list[ind],\n",
    "                \"relation_list\": rel_list,\n",
    "            })\n",
    "    # merge\n",
    "    text_id2rel_list = {}\n",
    "    for sample in short_pred_sample_list:\n",
    "        text_id = sample[\"id\"]\n",
    "        if text_id not in text_id2rel_list:\n",
    "            text_id2rel_list[text_id] = sample[\"relation_list\"]\n",
    "        else:\n",
    "            text_id2rel_list[text_id].extend(sample[\"relation_list\"])\n",
    "\n",
    "    text_id2text = {sample[\"id\"]:sample[\"text\"] for sample in test_data}\n",
    "    merged_pred_sample_list = []\n",
    "    for text_id, rel_list in text_id2rel_list.items():\n",
    "        merged_pred_sample_list.append({\n",
    "            \"id\": text_id,\n",
    "            \"text\": text_id2text[text_id],\n",
    "            \"relation_list\": filter_duplicates(rel_list),\n",
    "        })\n",
    "    return merged_pred_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 552it [00:00, 2000.76it/s]\n",
      "Predicting: 100%|██████████| 18/18 [00:04<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_sample_list = predict(short_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in pred_sample_list if len(s[\"relation_list\"]) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id2gold_n_pred = {}\n",
    "for sample in test_data:\n",
    "    text_id = sample[\"id\"]\n",
    "    text_id2gold_n_pred[text_id] = {\n",
    "        \"gold_relation_list\": sample[\"relation_list\"],\n",
    "    }\n",
    "def get_test_prf(pred_sample_list):\n",
    "    for sample in pred_sample_list:\n",
    "        text_id = sample[\"id\"]\n",
    "        text_id2gold_n_pred[text_id][\"pred_relation_list\"] = sample[\"relation_list\"]\n",
    "\n",
    "    correct_num, pred_num, gold_num = 0, 0, 0\n",
    "    for gold_n_pred in text_id2gold_n_pred.values():\n",
    "        gold_rel_list = gold_n_pred[\"gold_relation_list\"]\n",
    "        pred_rel_list = gold_n_pred[\"pred_relation_list\"] if \"pred_relation_list\" in gold_n_pred else []\n",
    "        gold_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in gold_rel_list])\n",
    "        pred_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in pred_rel_list])\n",
    "\n",
    "        for rel_str in pred_rel_set:\n",
    "            if rel_str in gold_rel_set:\n",
    "                correct_num += 1\n",
    "\n",
    "        pred_num += len(gold_rel_set)\n",
    "        gold_num += len(pred_rel_set)\n",
    "\n",
    "    prf = get_scores(correct_num, pred_num, gold_num)\n",
    "#     print(prf)\n",
    "    return prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5972972972971359, 0.518779342722883, 0.5552763818596557)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model state 16: (0.9112068965517129, 0.9034188034187924, 0.9072961372890456)\n",
    "# model state 17: (0.9060344827586095, 0.9096191889218483, 0.9078232970872052)\n",
    "# 18: (0.9178571428571316, 0.904600072824361, 0.9111803899493801)\n",
    "get_test_prf(pred_sample_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
