{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from IPython.core.debugger import set_trace\n",
    "from pprint import pprint\n",
    "import unicodedata\n",
    "from transformers import AutoModel, BasicTokenizer, BertTokenizerFast\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0 will be used\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device {} will be used\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "max_seq_len = 109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_home = \"/home/wangyucheng/opt/transformers_models_h5\"\n",
    "project_root = \"/home/wangyucheng/opt/data/research/relextr\"\n",
    "data_home = os.path.join(project_root, \"data\")\n",
    "\n",
    "experiment = \"only_shaking+roberta+restartwarm@webnlg\"\n",
    "model_state_dict_dir = os.path.join(project_root, \"state_dict\", experiment, \"model\")\n",
    "schedule_state_dict_dir = os.path.join(project_root, \"state_dict\", experiment, \"opt_schedule\")\n",
    "\n",
    "if not os.path.exists(model_state_dict_dir):\n",
    "    os.makedirs(model_state_dict_dir)\n",
    "if not os.path.exists(schedule_state_dict_dir):\n",
    "    os.makedirs(schedule_state_dict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "webnlg_data_dir = os.path.join(data_home, \"webnlg\", \"original\")\n",
    "webnlg_train_data_dir = os.path.join(webnlg_data_dir, \"train\")\n",
    "webnlg_valid_data_dir = os.path.join(webnlg_data_dir, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "webnlg_train_data_file_path_list = glob.glob(webnlg_train_data_dir + \"/*/*.xml\")\n",
    "webnlg_valid_data_file_path_list = glob.glob(webnlg_valid_data_dir + \"/*/*.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_sample_list(file_path_list):\n",
    "    all_entry_list = []\n",
    "    for file_path in tqdm(file_path_list, desc = \"Loading entries\"):\n",
    "        soup = BeautifulSoup(open(file_path, \"r\", encoding = \"utf-8\"), \"lxml\")\n",
    "        entry_list = soup.select(\"entry\")\n",
    "        all_entry_list.extend(entry_list)\n",
    "\n",
    "    normal_sample_list = []\n",
    "    sent2spo_list = {}\n",
    "    for entry in tqdm(all_entry_list, desc = \"Transforming into normal format\"):\n",
    "        sents = [lex.get_text() for lex in entry.select(\"lex\")]\n",
    "        spo_list = [[re.sub(\"_\", \" \", e.strip()) for e in triple.get_text().split(\"|\")] for triple in entry.select(\"modifiedtripleset > mtriple\")]\n",
    "        spo_list = [{\"subject\": spo[0], \"predicate\": spo[1], \"object\": spo[2]} for spo in spo_list]\n",
    "        for sent in sents:\n",
    "            if sent not in sent2spo_list:\n",
    "                sent2spo_list[sent] = spo_list\n",
    "            else:\n",
    "                sent2spo_list[sent].extend(spo_list)\n",
    "    for sent, spo_list in sent2spo_list.items():\n",
    "        # filter duplicates\n",
    "        spo_memory = set()\n",
    "        filtered_spo_list = []\n",
    "        for spo in spo_list:\n",
    "            memory = \"{}\\u2E80{}\\u2E80{}\".format(spo[\"subject\"], spo[\"predicate\"], spo[\"object\"])\n",
    "            if memory in spo_memory:\n",
    "                continue\n",
    "            if spo[\"subject\"] not in sent or spo[\"object\"] not in sent:\n",
    "                continue\n",
    "            filtered_spo_list.append(spo)\n",
    "            spo_memory.add(memory)\n",
    "        if len(filtered_spo_list) == 0:\n",
    "            continue\n",
    "        normal_sample_list.append({\n",
    "            \"text\": sent,\n",
    "            \"relation_list\": filtered_spo_list,\n",
    "        })\n",
    "    return normal_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading entries: 100%|██████████| 52/52 [00:10<00:00,  5.13it/s]\n",
      "Transforming into normal format: 100%|██████████| 6940/6940 [00:08<00:00, 772.74it/s] \n",
      "Loading entries: 100%|██████████| 52/52 [00:01<00:00, 43.88it/s]\n",
      "Transforming into normal format: 100%|██████████| 872/872 [00:01<00:00, 782.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12995\n",
      "1671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_normal_sample_list = get_normal_sample_list(webnlg_train_data_file_path_list)\n",
    "valid_normal_sample_list = get_normal_sample_list(webnlg_valid_data_file_path_list)\n",
    "print(len(train_normal_sample_list))\n",
    "print(len(valid_normal_sample_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data into train and valid set, take original valid set as test set \n",
    "random.seed(233)\n",
    "random.shuffle(train_normal_sample_list)\n",
    "train_data, valid_data = train_normal_sample_list[:-2000], train_normal_sample_list[-2000:]\n",
    "test_data = valid_normal_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14666/14666 [00:00<00:00, 779453.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# add text id\n",
    "text_id = 0\n",
    "for sample in tqdm(train_data + valid_data + test_data):\n",
    "    sample[\"id\"] = text_id\n",
    "    text_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(pretrained_model_home, \"bert-base-cased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path, add_special_tokens = False, do_lower_case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_char_ind2tok_ind(offset_map):\n",
    "    char_num = None\n",
    "    for tok_ind in range(len(offset_map) - 1, -1, -1):\n",
    "        if offset_map[tok_ind][1] != 0:\n",
    "            char_num = offset_map[tok_ind][1]\n",
    "            break\n",
    "    char_ind2tok_ind = [0 for _ in range(char_num)] # 除了空格(0)，其他字符均有对应token\n",
    "    for tok_ind, sp in enumerate(offset_map):\n",
    "        for char_ind in range(sp[0], sp[1]):\n",
    "            char_ind2tok_ind[char_ind] = tok_ind\n",
    "    return char_ind2tok_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ent2char_spans(text, entities):\n",
    "    entities = sorted(entities, key = lambda x: len(x), reverse = True)\n",
    "    text_cp = text[:]\n",
    "    ent2char_spans = {}\n",
    "    for ent in entities:\n",
    "        spans = []\n",
    "        for m in re.finditer(re.escape(ent), text_cp):\n",
    "            spans.append(m.span())\n",
    "        ent2char_spans[ent] = spans\n",
    "    return ent2char_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_sp2tok_sp(span, char_ind2tok_ind):\n",
    "    tok_span = (char_ind2tok_ind[span[0]], char_ind2tok_ind[span[1] - 1] + 1)\n",
    "    return tok_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ent2tok_spans(text, entities):\n",
    "    ent2char_spans = get_ent2char_spans(text, entities)\n",
    "    offset_map = tokenizer.encode_plus(text, \n",
    "                                       return_offsets_mapping = True, \n",
    "                                       add_special_tokens = False)[\"offset_mapping\"]\n",
    "    char_ind2tok_ind = get_char_ind2tok_ind(offset_map)\n",
    "    ent2tok_spans = {}\n",
    "    for ent, char_spans in ent2char_spans.items():\n",
    "        tok_spans = [char_sp2tok_sp(sp, char_ind2tok_ind) for sp in char_spans]\n",
    "        ent2tok_spans[ent] = tok_spans\n",
    "    return ent2tok_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test get_ent2tok_spans # debug\n",
    "# sample = train_data[0]\n",
    "# entities = [rel[\"subject\"] for rel in sample[\"relation_list\"]]\n",
    "# entities.extend([rel[\"object\"] for rel in sample[\"relation_list\"]])\n",
    "# get_ent2tok_spans(sample[\"text\"], entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14666/14666 [00:11<00:00, 1262.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# check token level span\n",
    "dif_ent_pairs = []\n",
    "for sample in tqdm(train_data + valid_data + test_data):\n",
    "    entities = [rel[\"subject\"] for rel in sample[\"relation_list\"]]\n",
    "    entities.extend([rel[\"object\"] for rel in sample[\"relation_list\"]])\n",
    "    ent2tok_spans = get_ent2tok_spans(sample[\"text\"], entities)\n",
    "    offset_map = tokenizer.encode_plus(sample[\"text\"], \n",
    "                                       return_offsets_mapping = True, \n",
    "                                       add_special_tokens = False)[\"offset_mapping\"]\n",
    "    for ent, tok_spans in ent2tok_spans.items():\n",
    "        for sp in tok_spans:\n",
    "            char_span_list = offset_map[sp[0]:sp[1]]\n",
    "            char_span = (char_span_list[0][0], char_span_list[-1][1])\n",
    "            decoded_ent = sample[\"text\"][char_span[0]:char_span[1]]\n",
    "            if ent != decoded_ent:\n",
    "                dif_ent_pairs.append((ent, decoded_ent))\n",
    "#             assert ent == decoded_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14666/14666 [00:08<00:00, 1716.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# add span\n",
    "for sample in tqdm(train_data + valid_data + test_data):\n",
    "    entities = [rel[\"subject\"] for rel in sample[\"relation_list\"]]\n",
    "    entities.extend([rel[\"object\"] for rel in sample[\"relation_list\"]])\n",
    "    ent2tok_spans = get_ent2tok_spans(sample[\"text\"], entities)\n",
    "    \n",
    "    new_relation_list = []\n",
    "    for rel in sample[\"relation_list\"]:\n",
    "        subj_spans = ent2tok_spans[rel[\"subject\"]]\n",
    "        obj_spans = ent2tok_spans[rel[\"object\"]]\n",
    "        if len(subj_spans) == 0 or len(obj_spans) == 0:\n",
    "            set_trace()\n",
    "        for subj_sp in subj_spans:\n",
    "            for obj_sp in obj_spans:\n",
    "                new_relation_list.append({\n",
    "                    \"subject\": rel[\"subject\"],\n",
    "                    \"object\": rel[\"object\"],\n",
    "                    \"subj_span\": subj_sp,\n",
    "                    \"obj_span\": obj_sp,\n",
    "                    \"predicate\": rel[\"predicate\"],\n",
    "                })\n",
    "    sample[\"relation_list\"] = new_relation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check if any empty relation list\n",
    "# for sample in tqdm(train_data + valid_data + test_data):\n",
    "#     if len(sample[\"relation_list\"]) == 0:\n",
    "#         set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14666/14666 [00:00<00:00, 249080.48it/s]\n"
     ]
    }
   ],
   "source": [
    "rel_set = set()\n",
    "for sample in tqdm(train_data + valid_data + test_data):\n",
    "    for rel in sample[\"relation_list\"]:\n",
    "        rel_set.add(rel[\"predicate\"])\n",
    "rel_set = sorted(rel_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id = {rel:ind for ind, rel in enumerate(rel_set)}\n",
    "id2rel = {ind:rel for rel, ind in rel2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spots(sample):\n",
    "    '''\n",
    "    spot: (rel_id, span_pos1, span_pos2, tag_id)\n",
    "    tag_id: \n",
    "        ent_matrix_spots: 0.other, 1.entity\n",
    "        head_rel_matrix_spots: 0.other, 1.subj head -> obj head 2. obj head -> subj head\n",
    "        tail_rel_matrix_spots: 0.other, 1.subj tail -> obj tail 2. obj tail -> subj tail\n",
    "    '''\n",
    "    matrix_spots = [] \n",
    "    spot_memory_set = set()\n",
    "    def add_spot(spot):\n",
    "        memory = \"{},{},{},{}\".format(*spot)\n",
    "        if memory not in spot_memory_set:\n",
    "            matrix_spots.append(spot)\n",
    "            spot_memory_set.add(memory)\n",
    "            \n",
    "    for rel in sample[\"relation_list\"]:\n",
    "        subj_span = rel[\"subj_span\"]\n",
    "        obj_span = rel[\"obj_span\"]\n",
    "        # entity head and tail: 1\n",
    "        add_spot((rel2id[rel[\"predicate\"]], subj_span[0], subj_span[1] - 1, 1))\n",
    "        add_spot((rel2id[rel[\"predicate\"]], obj_span[0], obj_span[1] - 1, 1))\n",
    "        if  subj_span[0] <= obj_span[0]:\n",
    "            # subj head -> obj head: 2\n",
    "            add_spot((rel2id[rel[\"predicate\"]], subj_span[0], obj_span[0], 2))\n",
    "        else:\n",
    "            # obj head -> subj head: 4\n",
    "            add_spot((rel2id[rel[\"predicate\"]], obj_span[0], subj_span[0], 4))\n",
    "            \n",
    "        if subj_span[1] <= obj_span[1]:\n",
    "            # subj tail -> obj tail: 3\n",
    "            add_spot((rel2id[rel[\"predicate\"]], subj_span[1] - 1, obj_span[1] - 1, 3))\n",
    "        else:\n",
    "            # obj tail -> subj tail: 5\n",
    "            add_spot((rel2id[rel[\"predicate\"]], obj_span[1] - 1, subj_span[1] - 1, 5))\n",
    "            \n",
    "    return matrix_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_size = max_seq_len\n",
    "shaking_ind2matrix_ind = [(ind, end_ind) for ind in range(matrix_size) for end_ind in list(range(matrix_size))[ind:]]\n",
    "\n",
    "matrix_ind2shaking_ind = [[0 for i in range(matrix_size)] for j in range(matrix_size)]\n",
    "for shaking_ind, matrix_ind in enumerate(shaking_ind2matrix_ind):\n",
    "    matrix_ind2shaking_ind[matrix_ind[0]][matrix_ind[1]] = shaking_ind\n",
    "    \n",
    "def get_shaking_ind2matrix_ind():\n",
    "    '''\n",
    "    return: e.g. [(0, 0), (0, 1), (0, 2), (1, 1), (1, 2), (2, 2)]\n",
    "    \n",
    "    '''\n",
    "    return shaking_ind2matrix_ind\n",
    "\n",
    "def get_matrix_ind2shaking_ind():\n",
    "    return matrix_ind2shaking_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spots2shaking_tag(spots):\n",
    "    '''\n",
    "    convert spots to shaking seq tag\n",
    "    spots: [(predicate_id, start_ind, end_ind, tag_id), ]\n",
    "    return: shake_seq_tag\n",
    "    '''\n",
    "    matrix_ind2shaking_ind = get_matrix_ind2shaking_ind()\n",
    "    shaking_seq_len = matrix_size * (matrix_size + 1) // 2\n",
    "    shaking_seq_tag = torch.zeros(len(rel2id), shaking_seq_len).long()\n",
    "    for sp in spots:\n",
    "        shaking_ind = matrix_ind2shaking_ind[sp[1]][sp[2]]\n",
    "        tag_id = sp[3]\n",
    "        shaking_seq_tag[sp[0]][shaking_ind] += 2**(tag_id - 1)\n",
    "    return shaking_seq_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spots2shaking_tag4batch(batch_spots):\n",
    "    '''\n",
    "    convert spots to batch shaking seq tag\n",
    "    因长序列的stack是费时操作，所以写这个函数转用作生成批量shaking tag\n",
    "    如果每个样本生成一条shaking tag再stack，一个32的batch耗时1s，太昂贵\n",
    "    spots: [(predicate_id, start_ind, end_ind, tag_id), ]\n",
    "    return: \n",
    "        batch_shake_seq_tag: (batch_size, rel_size, shaking_seq_len)\n",
    "    '''\n",
    "    matrix_ind2shaking_ind = get_matrix_ind2shaking_ind()\n",
    "    shaking_seq_len = matrix_size * (matrix_size + 1) // 2\n",
    "    batch_shaking_seq_tag = torch.zeros(len(batch_spots), len(rel2id), shaking_seq_len).long()\n",
    "    for batch_id, spots in enumerate(batch_spots):\n",
    "        for sp in spots:\n",
    "            shaking_ind = matrix_ind2shaking_ind[sp[1]][sp[2]]\n",
    "            tag_id = sp[3]\n",
    "            rel_id = sp[0]\n",
    "            batch_shaking_seq_tag[batch_id][rel_id][shaking_ind] += 2**(tag_id - 1)\n",
    "    return batch_shaking_seq_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spots_fr_shaking_tag(shaking_tag):\n",
    "    spots = []\n",
    "    shaking_ind2matrix_ind = get_shaking_ind2matrix_ind()\n",
    "#     %timeit shaking_tag.nonzero() # 4.5ms\n",
    "    for shaking_inds in shaking_tag.nonzero():\n",
    "        rel_id = shaking_inds[0].item()\n",
    "        matrix_inds = shaking_ind2matrix_ind[shaking_inds[1]]\n",
    "        tag_id_sum = shaking_tag[rel_id][shaking_inds[1]].item()\n",
    "        for tag_id in range(1, 6):\n",
    "            if tag_id_sum & 2**(tag_id - 1) != 0:\n",
    "                spot = (rel_id, matrix_inds[0], matrix_inds[1], tag_id)\n",
    "                spots.append(spot)\n",
    "    return spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check spots decoding\n",
    "# sample = train_data[0]\n",
    "# # pprint(sample)\n",
    "# matrix_spots = get_spots(sample)\n",
    "# print(matrix_spots)\n",
    "# shaking_tag = spots2shaking_tag(matrix_spots)\n",
    "# # %timeit spots2shaking_tag(matrix_spots)\n",
    "# decoded_spots = get_spots_fr_shaking_tag(shaking_tag)\n",
    "# # %timeit get_spots_fr_shaking_tag(shaking_tag) # 5ms\n",
    "# print(decoded_spots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_rel_fr_shaking_tag(text, shaking_tag, offset_map):\n",
    "    '''\n",
    "    shaking_tag: size = (rel_size, shaking_seq_len, )\n",
    "    '''\n",
    "    rel_list = []\n",
    "    \n",
    "    matrix_spots = get_spots_fr_shaking_tag(shaking_tag)\n",
    "#     spots = sorted(spots, key = lambda sp: (sp[0], sp[3])) # group by relation id, and entity first\n",
    "\n",
    "    # entity\n",
    "    head_ind2entities = {}\n",
    "    for sp in matrix_spots:\n",
    "        tag_id = sp[3]\n",
    "        if tag_id != 1:\n",
    "            continue\n",
    "            \n",
    "        rel_id = sp[0]\n",
    "        \n",
    "        char_span_list = offset_map[sp[1]:sp[2] + 1]\n",
    "        char_sp = (char_span_list[0][0], char_span_list[-1][1])\n",
    "        ent_text = text[char_sp[0]:char_sp[1]] \n",
    "        \n",
    "        rel_head_key = \"{}-{}\".format(rel_id, sp[1])\n",
    "        if rel_head_key not in head_ind2entities:\n",
    "            head_ind2entities[rel_head_key] = []\n",
    "        head_ind2entities[rel_head_key].append({\n",
    "            \"text\": ent_text,\n",
    "            \"span\": (sp[1], sp[2] + 1),\n",
    "        })\n",
    "        \n",
    "    # tail relation\n",
    "    tail_rel_memory_set = set()\n",
    "    for sp in matrix_spots:\n",
    "        rel_id = sp[0]\n",
    "        tag_id = sp[3]\n",
    "        if tag_id == 3:\n",
    "            tail_rel_memory = \"{}-{}-{}\".format(rel_id, sp[1], sp[2])\n",
    "            tail_rel_memory_set.add(tail_rel_memory)\n",
    "        elif tag_id == 5:\n",
    "            tail_rel_memory = \"{}-{}-{}\".format(rel_id, sp[2], sp[1])\n",
    "            tail_rel_memory_set.add(tail_rel_memory)\n",
    "\n",
    "    # head relation\n",
    "    for sp in matrix_spots:\n",
    "        rel_id = sp[0]\n",
    "        tag_id = sp[3]\n",
    "        \n",
    "        if tag_id == 2:\n",
    "            subj_head_key, obj_head_key = \"{}-{}\".format(rel_id, sp[1]), \"{}-{}\".format(rel_id, sp[2])\n",
    "            if subj_head_key not in head_ind2entities or obj_head_key not in head_ind2entities:\n",
    "                continue\n",
    "            subj_list = head_ind2entities[subj_head_key]\n",
    "            obj_list = head_ind2entities[obj_head_key]\n",
    "\n",
    "            for subj in subj_list:\n",
    "                for obj in obj_list:\n",
    "                    tail_rel_memory = \"{}-{}-{}\".format(rel_id, subj[\"span\"][1] - 1, obj[\"span\"][1] - 1)\n",
    "                    if tail_rel_memory not in tail_rel_memory_set:\n",
    "                        continue\n",
    "                    rel_list.append({\n",
    "                        \"subject\": subj[\"text\"],\n",
    "                        \"object\": obj[\"text\"],\n",
    "                        \"subj_span\": subj[\"span\"],\n",
    "                        \"obj_span\": obj[\"span\"],\n",
    "                        \"predicate\": id2rel[rel_id],\n",
    "                    })\n",
    "        elif tag_id == 4:\n",
    "            subj_head_key, obj_head_key = \"{}-{}\".format(rel_id, sp[2]), \"{}-{}\".format(rel_id, sp[1])\n",
    "            if subj_head_key not in head_ind2entities or obj_head_key not in head_ind2entities:\n",
    "                continue\n",
    "            subj_list = head_ind2entities[subj_head_key]\n",
    "            obj_list = head_ind2entities[obj_head_key]\n",
    "\n",
    "            for subj in subj_list:\n",
    "                for obj in obj_list:\n",
    "                    tail_rel_memory = \"{}-{}-{}\".format(rel_id, subj[\"span\"][1] - 1, obj[\"span\"][1] - 1)\n",
    "                    if tail_rel_memory not in tail_rel_memory_set:\n",
    "                        continue\n",
    "                    rel_list.append({\n",
    "                        \"subject\": subj[\"text\"],\n",
    "                        \"object\": obj[\"text\"],\n",
    "                        \"subj_span\": subj[\"span\"],\n",
    "                        \"obj_span\": obj[\"span\"],\n",
    "                        \"predicate\": id2rel[rel_id],\n",
    "                    })\n",
    "    return rel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_to(sample1, sample2):\n",
    "    assert sample1[\"id\"] == sample2[\"id\"]\n",
    "    assert sample1[\"text\"] == sample2[\"text\"]\n",
    "    memory_set = set()\n",
    "    for rel in sample2[\"relation_list\"]:\n",
    "        memory = \"{}\\u2E80{}\\u2E80{}\".format(str(rel[\"subj_span\"]), \n",
    "                                             rel[\"predicate\"], \n",
    "                                             str(rel[\"obj_span\"]))\n",
    "        memory_set.add(memory)\n",
    "    for rel in sample1[\"relation_list\"]:\n",
    "        memory = \"{}\\u2E80{}\\u2E80{}\".format(str(rel[\"subj_span\"]), \n",
    "                                             rel[\"predicate\"], \n",
    "                                             str(rel[\"obj_span\"]))\n",
    "        if memory not in memory_set:\n",
    "            set_trace()\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_data[102]\n",
    "# matrix_spots = get_spots(sample) # 79 us\n",
    "# # print(matrix_spots)\n",
    "# shaking_tag = spots2shaking_tag(matrix_spots) # 10 ms\n",
    "# # %timeit spots2shaking_tag(matrix_spots)\n",
    "# text = sample[\"text\"]\n",
    "# offset_map = tokenizer.encode_plus(text, return_offsets_mapping = True, \n",
    "#                                    add_special_tokens = False)[\"offset_mapping\"]\n",
    "\n",
    "# decoded_rel_list = decode_rel_fr_shaking_tag(text, \n",
    "#                                              shaking_tag, \n",
    "#                                              offset_map) # 4ms\n",
    "# # %timeit decode_rel_fr_shaking_tag(text, shaking_tag, offset_map)\n",
    "# pred_sample = {\n",
    "#     \"id\": sample[\"id\"],\n",
    "#     \"text\": text,\n",
    "#     \"relation_list\": decoded_rel_list,\n",
    "# }\n",
    "# # print(sample)\n",
    "# # print()\n",
    "# # print(pred_sample)\n",
    "# sample_equal_to(sample, pred_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check tagging and decoding\n",
    "# for sample in tqdm(train_data + valid_data + test_data):\n",
    "#     matrix_spots = get_spots(sample)\n",
    "#     shaking_tag = spots2shaking_tag(matrix_spots)\n",
    "\n",
    "#     text = sample[\"text\"]\n",
    "#     offset_map = tokenizer.encode_plus(text, return_offsets_mapping = True, \n",
    "#                                        add_special_tokens = False)[\"offset_mapping\"]\n",
    "#     decoded_rel_list = decode_rel_fr_shaking_tag(text, \n",
    "#                                                  shaking_tag,\n",
    "#                                                  offset_map)\n",
    "#     pred_sample = {\n",
    "#         \"id\": sample[\"id\"],\n",
    "#         \"text\": text,\n",
    "#         \"relation_list\": decoded_rel_list,\n",
    "#     }\n",
    "#     if not sample_equal_to(pred_sample, sample):\n",
    "#         set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check batch tagging and decoding\n",
    "# batch_spots = []\n",
    "# batch_samples = train_data[:100]\n",
    "# for sample in tqdm(batch_samples):\n",
    "#     batch_spots.append(get_spots(sample))\n",
    "# batch_shaking_tag = spots2shaking_tag4batch(batch_spots)\n",
    "\n",
    "# for ind, sample in tqdm(enumerate(batch_samples)):\n",
    "#     text = sample[\"text\"]\n",
    "#     offset_map = tokenizer.encode_plus(text, return_offsets_mapping = True, \n",
    "#                                        add_special_tokens = False)[\"offset_mapping\"]\n",
    "#     shaking_tag = batch_shaking_tag[ind]\n",
    "#     decoded_rel_list = decode_rel_fr_shaking_tag(text, \n",
    "#                                                  shaking_tag,\n",
    "#                                                  offset_map)\n",
    "#     pred_sample = {\n",
    "#         \"id\": sample[\"id\"],\n",
    "#         \"text\": text,\n",
    "#         \"relation_list\": decoded_rel_list,\n",
    "#     }\n",
    "#     if not sample_equal_to(pred_sample, sample):\n",
    "#         set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexed_train_valid_data(data):\n",
    "    indexed_samples = []\n",
    "    for ind, sample in tqdm(enumerate(data), desc = \"Generate indexed train or valid data\"):\n",
    "        text = sample[\"text\"]\n",
    "        text_id = sample[\"id\"]\n",
    "        # codes for bert input\n",
    "        codes = tokenizer.encode_plus(text, \n",
    "                                    return_offsets_mapping = True, \n",
    "                                    add_special_tokens = False,\n",
    "                                    max_length = max_seq_len, \n",
    "                                    pad_to_max_length = True)\n",
    "        \n",
    "        \n",
    "        # tagging\n",
    "        matrix_spots = get_spots(sample)\n",
    "        \n",
    "        # get codes\n",
    "        input_ids = torch.tensor(codes[\"input_ids\"]).long()\n",
    "        attention_mask = torch.tensor(codes[\"attention_mask\"]).long()\n",
    "        token_type_ids = torch.tensor(codes[\"token_type_ids\"]).long()\n",
    "        offset_map = codes[\"offset_mapping\"]\n",
    "\n",
    "        sample_tp = (text_id,\n",
    "                     text, \n",
    "                     input_ids,\n",
    "                     attention_mask,\n",
    "                     token_type_ids,\n",
    "                     offset_map,\n",
    "                     matrix_spots,\n",
    "                    )\n",
    "        indexed_samples.append(sample_tp)       \n",
    "    return indexed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexed_pred_data(data):\n",
    "    indexed_samples = []\n",
    "    for ind, sample in tqdm(enumerate(data), desc = \"Generate indexed pred data\"):\n",
    "        text = sample[\"text\"] \n",
    "        text_id = sample[\"id\"]\n",
    "        codes = tokenizer.encode_plus(text, \n",
    "                                    return_offsets_mapping = True, \n",
    "                                    add_special_tokens = False,\n",
    "                                    max_length = max_seq_len, \n",
    "                                    pad_to_max_length = True)\n",
    "        \n",
    "        input_ids = torch.tensor(codes[\"input_ids\"]).long()\n",
    "        attention_mask = torch.tensor(codes[\"attention_mask\"]).long()\n",
    "        token_type_ids = torch.tensor(codes[\"token_type_ids\"]).long()\n",
    "        offset_map = codes[\"offset_mapping\"]\n",
    "\n",
    "        sample_tp = (text_id,\n",
    "                     text, \n",
    "                     input_ids,\n",
    "                     attention_mask,\n",
    "                     token_type_ids,\n",
    "                     offset_map,\n",
    "                     )\n",
    "        indexed_samples.append(sample_tp)       \n",
    "    return indexed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_dev_batch(batch_data):\n",
    "    text_id_list = []\n",
    "    text_list = []\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    token_type_ids_list = [] \n",
    "    offset_map_list = []\n",
    "    matrix_spots_list = []\n",
    "    \n",
    "    for sample in batch_data:\n",
    "        text_id_list.append(sample[0])\n",
    "        text_list.append(sample[1])\n",
    "        input_ids_list.append(sample[2])\n",
    "        attention_mask_list.append(sample[3])        \n",
    "        token_type_ids_list.append(sample[4])        \n",
    "        offset_map_list.append(sample[5])\n",
    "        \n",
    "        matrix_spots_list.append(sample[6])\n",
    "    \n",
    "    batch_input_ids = torch.stack(input_ids_list, dim = 0)\n",
    "    batch_attention_mask = torch.stack(attention_mask_list, dim = 0)\n",
    "    batch_token_type_ids = torch.stack(token_type_ids_list, dim = 0)\n",
    "\n",
    "    batch_shaking_tag = spots2shaking_tag4batch(matrix_spots_list)\n",
    "#     batch_shaking_tag = torch.stack(shaking_tag_list, dim = 0)\n",
    "    return text_id_list, text_list, batch_input_ids, batch_attention_mask, batch_token_type_ids, offset_map_list, batch_shaking_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pred_batch(batch_data):\n",
    "    text_ids = []\n",
    "    text_list = []\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    token_type_ids = [] \n",
    "    offset_map = []\n",
    "    for sample in batch_data:\n",
    "        text_ids.append(sample[0])\n",
    "        text_list.append(sample[1])\n",
    "        input_ids.append(sample[2])\n",
    "        attention_mask.append(sample[3])        \n",
    "        token_type_ids.append(sample[4])        \n",
    "        offset_map.append(sample[5])\n",
    "    input_ids = torch.stack(input_ids, dim = 0)\n",
    "    attention_mask = torch.stack(attention_mask, dim = 0)\n",
    "    token_type_ids = torch.stack(token_type_ids, dim = 0)\n",
    "    return text_ids, text_list, input_ids, attention_mask, token_type_ids, offset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @uni\n",
    "def get_train_dev_dataloader_gen(indexed_train_sample_list, indexed_dev_sample_list, batch_size):\n",
    "    train_dataloader = DataLoader(MyDataset(indexed_train_sample_list), \n",
    "                                      batch_size = batch_size, \n",
    "                                      shuffle = True, \n",
    "                                      num_workers = 0,\n",
    "                                      drop_last = False,\n",
    "                                      collate_fn = generate_train_dev_batch,\n",
    "                                     )\n",
    "    dev_dataloader = DataLoader(MyDataset(indexed_dev_sample_list), \n",
    "                              batch_size = batch_size, \n",
    "                              shuffle = True, \n",
    "                              num_workers = 0,\n",
    "                              drop_last = False,\n",
    "                              collate_fn = generate_train_dev_batch,\n",
    "                             )\n",
    "    return train_dataloader, dev_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 10995it [00:05, 2195.31it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_train_data = get_indexed_train_valid_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 2000it [00:00, 2184.91it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_valid_data = get_indexed_train_valid_data(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at dataloader\n",
    "train_dataloader, dev_dataloader = get_train_dev_dataloader_gen(indexed_train_data, indexed_valid_data, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_iter = iter(train_dataloader)\n",
    "# %timeit next(train_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aenir written by Garth Nix is available in paperback with the OCLC number 45644811.\n",
      "\n",
      "Aenir written by Garth Nix is available in paperback with the OCLC number 45644811. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "torch.Size([24, 109])\n",
      "torch.Size([24, 109])\n",
      "torch.Size([24, 109])\n",
      "24\n",
      "torch.Size([24, 208, 5995])\n"
     ]
    }
   ],
   "source": [
    "train_data_iter = iter(train_dataloader)\n",
    "batch_data = next(train_data_iter)\n",
    "text_id_list, text_list, batch_input_ids, \\\n",
    "batch_attention_mask, batch_token_type_ids, \\\n",
    "offset_map_list, batch_shaking_tag = batch_data\n",
    "\n",
    "print(text_list[0])\n",
    "print()\n",
    "print(tokenizer.decode(batch_input_ids[0].tolist()))\n",
    "print(batch_input_ids.size())\n",
    "print(batch_attention_mask.size())\n",
    "print(batch_token_type_ids.size())\n",
    "print(len(offset_map_list))\n",
    "print(batch_shaking_tag.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shake_hands_afterwards(seq_hiddens):\n",
    "    '''\n",
    "    seq_hiddens: (batch_size, seq_len, hidden_size) (32, 3, 5)\n",
    "    return shake_hands_matrix_hiddens: (batch_size, (1 + seq_len) * seq_len / 2, hidden_size) (32, 5+4+3+2+1, 5)\n",
    "    '''\n",
    "    seq_len = seq_hiddens.size()[-2]\n",
    "    shake_hands_hidden_list = []\n",
    "    for ind in range(seq_len):\n",
    "        hidden_each_step = seq_hiddens[:, ind, :]\n",
    "        # seq_len - ind: only shake afterwards\n",
    "        repeat_hidden_each_step = hidden_each_step[:, None, :].repeat(1, seq_len - ind, 1) \n",
    "        shake_hands_hidden = torch.cat([repeat_hidden_each_step, seq_hiddens[:, ind:, :]], dim = -1)\n",
    "        shake_hands_hidden_list.append(shake_hands_hidden)\n",
    "    shake_hands_matrix_hiddens = torch.cat(shake_hands_hidden_list, dim = 1)\n",
    "    return shake_hands_matrix_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 尝试用卷积层代替全连接层做并行运算，因为for循环太慢。但repeat操作会成倍增加显存（200G），不现实\n",
    "# x = torch.tensor([[[1, 3, 4.], [2, 6, 8.]]])\n",
    "# x = x.repeat(1, 1, 2)\n",
    "# x = x.view(-1, x.size()[-1]).unsqueeze(-1)\n",
    "# print(x)\n",
    "# print(x.size())\n",
    "# conv_fc = nn.Conv1d(in_channels = 3 * 2, \n",
    "#                     out_channels = 4 * 2, \n",
    "#                     kernel_size = 1, \n",
    "#                     groups = 2)\n",
    "\n",
    "# outputs = conv_fc(x)\n",
    "# print(outputs.size())\n",
    "# print(outputs)\n",
    "\n",
    "# outputs = outputs.view(1, -1, 2, 4)\n",
    "# print(outputs.size())\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelExtractor(nn.Module):\n",
    "    def __init__(self, encoder, rel_size):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        hidden_size = encoder.config.hidden_size\n",
    "\n",
    "        self.shaking_fc_list = [nn.Linear(hidden_size * 2, 2**5) for _ in range(rel_size)]\n",
    "        \n",
    "        # register fcs\n",
    "        for ind, fc in enumerate(self.shaking_fc_list):\n",
    "            self.register_parameter(\"weight_4_ent_in_rel{}\".format(ind), fc.weight)\n",
    "            self.register_parameter(\"bias_4_ent_in_rel{}\".format(ind), fc.bias)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # input_ids, attention_mask, token_type_ids: (batch_size, seq_len)\n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "        # last_hidden_state: (batch_size, seq_len, hidden_size)\n",
    "        last_hidden_state = context_outputs[0]\n",
    "        \n",
    "        # shaking_hiddens: (batch_size, 1 + ... + seq_len, hidden_size)\n",
    "        shaking_hiddens = shake_hands_afterwards(last_hidden_state)\n",
    "        \n",
    "        shaking_outputs_list = []\n",
    "        for fc in self.shaking_fc_list:\n",
    "            shaking_outputs_list.append(fc(shaking_hiddens))\n",
    "\n",
    "        shaking_outputs = torch.stack(shaking_outputs_list, dim = 1)\n",
    "        return shaking_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = AutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extractor = RelExtractor(roberta, len(rel2id))\n",
    "rel_extractor = rel_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test model\n",
    "# batch_input_ids, \\\n",
    "# batch_attention_mask,\\\n",
    "# batch_token_type_ids = batch_input_ids.to(device), \\\n",
    "#                          batch_attention_mask.to(device), \\\n",
    "#                          batch_token_type_ids.to(device)\n",
    "                       \n",
    "# shaking_outputs = rel_extractor(batch_input_ids, \n",
    "#                                   batch_attention_mask, \n",
    "#                                   batch_token_type_ids)\n",
    "\n",
    "# print(shaking_outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_loss(weights = None):\n",
    "    if weights is not None:\n",
    "        weights = torch.FloatTensor(weights).to(device)\n",
    "    cross_en = nn.CrossEntropyLoss(weight = weights)  \n",
    "    return lambda pred, target: cross_en(pred.view(-1, pred.size()[-1]), target.view(-1))\n",
    "loss_func = bias_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_accuracy(pred, truth):\n",
    "    '''\n",
    "    计算所有抽取字段都正确的样本比例\n",
    "    即该batch的输出与truth全等的样本比例\n",
    "    '''\n",
    "    # (batch_size, ..., seq_len, tag_size) -> (batch_size, ..., seq_len)\n",
    "    pred_id = torch.argmax(pred, dim = -1)\n",
    "    # (batch_size, ..., seq_len) -> (batch_size, )，把每个sample压成一条seq\n",
    "    pred_id = pred_id.view(pred_id.size()[0], -1)\n",
    "    truth = truth.view(truth.size()[0], -1)\n",
    "    \n",
    "    # (batch_size, )，每个元素是pred与truth之间tag相同的数量\n",
    "    correct_tag_num = torch.sum(torch.eq(truth, pred_id).float(), dim = 1)\n",
    "\n",
    "    # seq维上所有tag必须正确，所以correct_tag_num必须等于seq的长度才算一个correct的sample\n",
    "    sample_acc_ = torch.eq(correct_tag_num, torch.ones_like(correct_tag_num) * truth.size()[-1]).float()\n",
    "    sample_acc = torch.mean(sample_acc_, axis=0)\n",
    "    \n",
    "    return sample_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_cpg(text_list, offset_map_list, \n",
    "                 batch_pred_shaking_outputs,\n",
    "                 batch_gold_shaking_tag):\n",
    "    batch_pred_shaking_tag = torch.argmax(batch_pred_shaking_outputs, dim = -1)\n",
    "    \n",
    "    correct_num, pred_num, gold_num = 0, 0, 0\n",
    "    for ind in range(len(text_list)):\n",
    "        text = text_list[ind]\n",
    "        offset_map = offset_map_list[ind]\n",
    "        gold_shaking_tag, pred_shaking_tag = batch_gold_shaking_tag[ind], batch_pred_shaking_tag[ind]\n",
    " \n",
    "        pred_rel_list = decode_rel_fr_shaking_tag(text, \n",
    "                                                  pred_shaking_tag,\n",
    "                                                  offset_map)\n",
    "        gold_rel_list = decode_rel_fr_shaking_tag(text, \n",
    "                                                  gold_shaking_tag,\n",
    "                                                  offset_map)\n",
    "\n",
    "        gold_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in gold_rel_list])\n",
    "        pred_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in pred_rel_list])\n",
    "        \n",
    "        for rel_str in pred_rel_set:\n",
    "            if rel_str in gold_rel_set:\n",
    "                correct_num += 1\n",
    "        \n",
    "        pred_num += len(gold_rel_set)\n",
    "        gold_num += len(pred_rel_set)\n",
    "        \n",
    "    return correct_num, pred_num, gold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(correct_num, pred_num, gold_num):\n",
    "    minimini = 1e-10\n",
    "    precision = correct_num / (pred_num + minimini)\n",
    "    recall = correct_num / (gold_num + minimini)\n",
    "    f1 = 2 * precision * recall / (precision + recall + minimini)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train step\n",
    "def train_step(train_data, optimizer):\n",
    "    text_id_list, text_list, batch_input_ids, \\\n",
    "    batch_attention_mask, batch_token_type_ids, \\\n",
    "    offset_map_list, batch_shaking_tag = train_data\n",
    "    \n",
    "    batch_input_ids, \\\n",
    "    batch_attention_mask, \\\n",
    "    batch_token_type_ids, \\\n",
    "    batch_shaking_tag = (batch_input_ids.to(device), \n",
    "                          batch_attention_mask.to(device), \n",
    "                          batch_token_type_ids.to(device), \n",
    "                          batch_shaking_tag.to(device)\n",
    "                         )\n",
    "    \n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                  batch_attention_mask, \n",
    "                                  batch_token_type_ids, \n",
    "                                 )\n",
    "    \n",
    "    # bp\n",
    "    loss = loss_func(shaking_outputs, batch_shaking_tag)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    sample_acc = get_sample_accuracy(shaking_outputs, \n",
    "                                          batch_shaking_tag)\n",
    "    \n",
    "    return loss.item(), sample_acc.item()\n",
    "\n",
    "# valid step\n",
    "def valid_step(valid_data):\n",
    "    text_id_list, text_list, batch_input_ids, \\\n",
    "    batch_attention_mask, batch_token_type_ids, \\\n",
    "    offset_map_list, batch_shaking_tag = valid_data\n",
    "    \n",
    "    batch_input_ids, \\\n",
    "    batch_attention_mask, \\\n",
    "    batch_token_type_ids, \\\n",
    "    batch_shaking_tag = (batch_input_ids.to(device), \n",
    "                          batch_attention_mask.to(device), \n",
    "                          batch_token_type_ids.to(device), \n",
    "                          batch_shaking_tag.to(device)\n",
    "                         )\n",
    "    with torch.no_grad():\n",
    "        shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                      batch_attention_mask, \n",
    "                                      batch_token_type_ids, \n",
    "                                     )\n",
    "    \n",
    "    sample_acc = get_sample_accuracy(shaking_outputs, \n",
    "                                      batch_shaking_tag)\n",
    "    \n",
    "    rel_cpg = get_rel_cpg(text_list, offset_map_list, \n",
    "                          shaking_outputs,\n",
    "                          batch_shaking_tag)\n",
    "    \n",
    "    return sample_acc.item(), rel_cpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = 0.\n",
    "def train_n_valid(train_dataloader, dev_dataloader, optimizer, scheduler, num_epoch):  \n",
    "    def train(dataloader, ep):\n",
    "        # train\n",
    "        rel_extractor.train()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        total_loss, total_sample_acc = 0., 0.\n",
    "        for batch_ind, train_data in enumerate(dataloader):\n",
    "            t_batch = time.time()\n",
    "            loss, sample_acc = train_step(train_data, optimizer)\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_sample_acc += sample_acc\n",
    "            \n",
    "            avg_loss = total_loss / (batch_ind + 1)\n",
    "            avg_sample_acc = total_sample_acc / (batch_ind + 1)\n",
    "            \n",
    "            batch_print_format = \"\\rEpoch: {}/{}, batch: {}/{}, train_loss: {}, \" + \\\n",
    "                                \"t_sample_acc: {},\" + \\\n",
    "                                 \"lr: {}, batch_time: {}, total_time: {} -------------\"\n",
    "                    \n",
    "            print(batch_print_format.format(ep + 1, num_epoch, \n",
    "                                            batch_ind + 1, len(dataloader), \n",
    "                                            avg_loss, \n",
    "                                            avg_sample_acc,\n",
    "                                            optimizer.param_groups[0]['lr'],\n",
    "                                            time.time() - t_batch,\n",
    "                                            time.time() - t_ep,\n",
    "                                           ), end=\"\")\n",
    "    def valid(dataloader, ep):\n",
    "        # valid\n",
    "        rel_extractor.eval()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        total_sample_acc = 0.\n",
    "        total_rel_correct_num, total_rel_pred_num, total_rel_gold_num = 0, 0, 0\n",
    "        for batch_ind, dev_data in enumerate(tqdm(dataloader, desc = \"Validating\")):\n",
    "            sample_acc, rel_cpg = valid_step(dev_data)\n",
    "\n",
    "            total_sample_acc += sample_acc\n",
    "            \n",
    "            total_rel_correct_num += rel_cpg[0]\n",
    "            total_rel_pred_num += rel_cpg[1]\n",
    "            total_rel_gold_num += rel_cpg[2]\n",
    "\n",
    "        avg_sample_acc = total_sample_acc / len(dataloader)\n",
    "        \n",
    "        rel_prf = get_scores(total_rel_correct_num, total_rel_pred_num, total_rel_gold_num)\n",
    "             \n",
    "        print_format = \"Epoch: {}/{}, val_sample_acc: {}, \" + \\\n",
    "                        \"val_rel_prec: {}, val_rel_rec: {}, val_rel_f1: {},\\n\" + \\\n",
    "                        \"val_time: {}\"\n",
    "        print(print_format.format(ep + 1, num_epoch,  \n",
    "                                  avg_sample_acc,\n",
    "                                  *rel_prf, \n",
    "                                  time.time() - t_ep,\n",
    "                                 ))\n",
    "        return rel_prf[2]\n",
    "        \n",
    "    for ep in range(num_epoch):\n",
    "        train(train_dataloader, ep)   \n",
    "        print()\n",
    "        valid_f1 = valid(dev_dataloader, ep)\n",
    "        \n",
    "        global max_f1\n",
    "        if valid_f1 >= max_f1: \n",
    "            max_f1 = valid_f1\n",
    "            if valid_f1 > 0.7: # save the best model\n",
    "                file_num = len(glob.glob(model_state_dict_dir + \"/*.pt\"))\n",
    "                torch.save(rel_extractor.state_dict(), os.path.join(model_state_dict_dir, \"model_state_dict_{}.pt\".format(file_num))) \n",
    "                torch.save(scheduler.state_dict(), os.path.join(schedule_state_dict_dir, \"scheduler_state_dict_{}.pt\".format(file_num))) \n",
    "        print(\"Current avf_f1: {}, Best f1: {}\".format(valid_f1, max_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_state_path(state_dir):\n",
    "    max_file_num = -1\n",
    "    last_state_path = None\n",
    "    for path in glob.glob(state_dir + \"/*.pt\"):\n",
    "        file_num = re.search(\"state_dict_(\\d+)\\.pt\", path).group(1)\n",
    "        if int(file_num) > max_file_num:\n",
    "            max_file_num = int(file_num)\n",
    "            last_state_path = path\n",
    "    return last_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing dataloader...\n",
      "dataloaders done!\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "print(\"preparing dataloader...\")\n",
    "train_dataloader, \\\n",
    "dev_dataloader = get_train_dev_dataloader_gen(indexed_train_data, \n",
    "                                            indexed_valid_data, \n",
    "                                            batch_size, \n",
    "                                            )\n",
    "print(\"dataloaders done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "init_learning_rate = 5e-5\n",
    "optimizer = torch.optim.Adam(rel_extractor.parameters(), lr = init_learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, len(train_dataloader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, batch: 1374/1375, train_loss: 0.05591354720241775, t_sample_acc: 0.0,lr: 2.5028559927002325e-05, batch_time: 1.7606003284454346, total_time: 2460.0167138576508 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 1/20, batch: 1375/1375, train_loss: 0.05587333338165825, t_sample_acc: 0.0,lr: 2.5000000000000008e-05, batch_time: 0.9092319011688232, total_time: 2460.9425253868103 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:32<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, val_sample_acc: 0.0, val_rel_prec: 0.0, val_rel_rec: 0.0, val_rel_f1: 0.0,\n",
      "val_time: 92.59789848327637\n",
      "Current avf_f1: 0.0, Best f1: 0.0\n",
      "Epoch: 2/20, batch: 1374/1375, train_loss: 0.000495179559847542, t_sample_acc: 0.0,lr: 1.6313393930156295e-11, batch_time: 1.7613189220428467, total_time: 2457.3490686416626 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 2/20, batch: 1375/1375, train_loss: 0.0004951634890696203, t_sample_acc: 0.0,lr: 5e-05, batch_time: 0.8829731941223145, total_time: 2458.2559745311737 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:30<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20, val_sample_acc: 0.0, val_rel_prec: 0.0, val_rel_rec: 0.0, val_rel_f1: 0.0,\n",
      "val_time: 90.53565335273743\n",
      "Current avf_f1: 0.0, Best f1: 0.0\n",
      "Epoch: 3/20, batch: 1374/1375, train_loss: 0.0002213461258051035, t_sample_acc: 0.0,lr: 2.5028559927002325e-05, batch_time: 1.7622177600860596, total_time: 2460.1938219070435 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 3/20, batch: 1375/1375, train_loss: 0.00022129190748620948, t_sample_acc: 0.0,lr: 2.5000000000000008e-05, batch_time: 0.8812675476074219, total_time: 2461.090471506119 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:32<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/20, val_sample_acc: 0.0, val_rel_prec: 0.0, val_rel_rec: 0.0, val_rel_f1: 0.0,\n",
      "val_time: 92.9315197467804\n",
      "Current avf_f1: 0.0, Best f1: 0.0\n",
      "Epoch: 4/20, batch: 1374/1375, train_loss: 0.00013934246172913787, t_sample_acc: 0.0,lr: 1.6313393930156295e-11, batch_time: 1.7619554996490479, total_time: 2465.8048458099365 -------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 4/20, batch: 1375/1375, train_loss: 0.0001394144866922447, t_sample_acc: 0.0,lr: 5e-05, batch_time: 0.8835532665252686, total_time: 2466.709825515747 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:32<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/20, val_sample_acc: 0.0, val_rel_prec: 0.0, val_rel_rec: 0.0, val_rel_f1: 0.0,\n",
      "val_time: 92.09782719612122\n",
      "Current avf_f1: 0.0, Best f1: 0.0\n",
      "Epoch: 5/20, batch: 1374/1375, train_loss: 0.00011600634373649985, t_sample_acc: 0.0,lr: 2.5028559927002325e-05, batch_time: 1.7495250701904297, total_time: 2466.1472256183624 -------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 5/20, batch: 1375/1375, train_loss: 0.0001159651218304961, t_sample_acc: 0.0,lr: 2.5000000000000008e-05, batch_time: 0.8820629119873047, total_time: 2467.0430574417114 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:32<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/20, val_sample_acc: 0.0, val_rel_prec: 0.0, val_rel_rec: 0.0, val_rel_f1: 0.0,\n",
      "val_time: 92.78888750076294\n",
      "Current avf_f1: 0.0, Best f1: 0.0\n",
      "Epoch: 6/20, batch: 1374/1375, train_loss: 9.921700558685742e-05, t_sample_acc: 0.0,lr: 1.6313393930156295e-11, batch_time: 1.7670164108276367, total_time: 2465.483920812607 ---------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 6/20, batch: 1375/1375, train_loss: 9.917968506025235e-05, t_sample_acc: 0.0,lr: 5e-05, batch_time: 0.8815395832061768, total_time: 2466.3890283107758 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:33<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/20, val_sample_acc: 0.0, val_rel_prec: 0.0, val_rel_rec: 0.0, val_rel_f1: 0.0,\n",
      "val_time: 93.07560300827026\n",
      "Current avf_f1: 0.0, Best f1: 0.0\n",
      "Epoch: 7/20, batch: 1374/1375, train_loss: 7.061909339068308e-05, t_sample_acc: 0.0,lr: 2.5028559927002325e-05, batch_time: 1.7627124786376953, total_time: 2461.3381419181824 -------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 7/20, batch: 1375/1375, train_loss: 7.060951090005057e-05, t_sample_acc: 0.0,lr: 2.5000000000000008e-05, batch_time: 0.8847787380218506, total_time: 2462.24200296402 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:32<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/20, val_sample_acc: 0.0, val_rel_prec: 0.0, val_rel_rec: 0.0, val_rel_f1: 0.0,\n",
      "val_time: 92.35467410087585\n",
      "Current avf_f1: 0.0, Best f1: 0.0\n",
      "Epoch: 8/20, batch: 1374/1375, train_loss: 5.209650205624037e-05, t_sample_acc: 0.0,lr: 1.6313393930156295e-11, batch_time: 1.7680702209472656, total_time: 2457.2851297855377 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 8/20, batch: 1375/1375, train_loss: 5.2096006303062575e-05, t_sample_acc: 0.0,lr: 5e-05, batch_time: 0.8844068050384521, total_time: 2458.1837944984436 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:31<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/20, val_sample_acc: 0.0025, val_rel_prec: 0.010826998387468076, val_rel_rec: 0.7580645161278096, val_rel_f1: 0.02134908016983201,\n",
      "val_time: 91.75291776657104\n",
      "Current avf_f1: 0.02134908016983201, Best f1: 0.02134908016983201\n",
      "Epoch: 9/20, batch: 1374/1375, train_loss: 3.624642441064088e-05, t_sample_acc: 0.010917030567685589,lr: 2.5028559927002325e-05, batch_time: 1.7616968154907227, total_time: 2459.0186688899994 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 9/20, batch: 1375/1375, train_loss: 3.623532440740911e-05, t_sample_acc: 0.01090909090909091,lr: 2.5000000000000008e-05, batch_time: 0.8807082176208496, total_time: 2459.913102388382 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:33<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/20, val_sample_acc: 0.059, val_rel_prec: 0.26791061967288027, val_rel_rec: 0.8042876901797508, val_rel_f1: 0.4019353723488823,\n",
      "val_time: 93.67486476898193\n",
      "Current avf_f1: 0.4019353723488823, Best f1: 0.4019353723488823\n",
      "Epoch: 10/20, batch: 1374/1375, train_loss: 2.35909072734893e-05, t_sample_acc: 0.048125909752547304,lr: 1.6313393930156295e-11, batch_time: 1.758556604385376, total_time: 2458.7368807792664 ----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 10/20, batch: 1375/1375, train_loss: 2.3589992674467133e-05, t_sample_acc: 0.048090909090909094,lr: 5e-05, batch_time: 0.8775858879089355, total_time: 2459.6380870342255 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:34<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/20, val_sample_acc: 0.0725, val_rel_prec: 0.4118866620594238, val_rel_rec: 0.7534766118836598, val_rel_f1: 0.5326184092482926,\n",
      "val_time: 94.28609156608582\n",
      "Current avf_f1: 0.5326184092482926, Best f1: 0.5326184092482926\n",
      "Epoch: 11/20, batch: 1374/1375, train_loss: 1.93703652762736e-05, t_sample_acc: 0.08642649199417758,lr: 2.5028559927002325e-05, batch_time: 1.7640302181243896, total_time: 2460.225976228714 ----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 11/20, batch: 1375/1375, train_loss: 1.936306426366421e-05, t_sample_acc: 0.08660606061328541,lr: 2.5000000000000008e-05, batch_time: 0.8817868232727051, total_time: 2461.133918762207 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:35<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/20, val_sample_acc: 0.1575, val_rel_prec: 0.6222068647776866, val_rel_rec: 0.6970322580644981, val_rel_f1: 0.6574975656755586,\n",
      "val_time: 95.41891622543335\n",
      "Current avf_f1: 0.6574975656755586, Best f1: 0.6574975656755586\n",
      "Epoch: 12/20, batch: 1374/1375, train_loss: 1.3654548929030257e-05, t_sample_acc: 0.17758369723435224,lr: 1.6313393930156295e-11, batch_time: 1.7563307285308838, total_time: 2461.918289422989 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 12/20, batch: 1375/1375, train_loss: 1.3662360651572023e-05, t_sample_acc: 0.17745454545454545,lr: 5e-05, batch_time: 0.8842799663543701, total_time: 2462.818258047104 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:33<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/20, val_sample_acc: 0.204, val_rel_prec: 0.6602165399677341, val_rel_rec: 0.7654914529914325, val_rel_f1: 0.7089672232031926,\n",
      "val_time: 93.62155079841614\n",
      "Current avf_f1: 0.7089672232031926, Best f1: 0.7089672232031926\n",
      "Epoch: 13/20, batch: 1374/1375, train_loss: 1.2507895986230653e-05, t_sample_acc: 0.19068413391557495,lr: 2.5028559927002325e-05, batch_time: 1.761150598526001, total_time: 2459.3586146831512 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 13/20, batch: 1375/1375, train_loss: 1.2505258118835628e-05, t_sample_acc: 0.1907878787951036,lr: 2.5000000000000008e-05, batch_time: 0.8808040618896484, total_time: 2460.2542552948 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:35<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/20, val_sample_acc: 0.304, val_rel_prec: 0.7383091453581954, val_rel_rec: 0.7919446503582706, val_rel_f1: 0.7641869336648739,\n",
      "val_time: 95.2155933380127\n",
      "Current avf_f1: 0.7641869336648739, Best f1: 0.7641869336648739\n",
      "Epoch: 14/20, batch: 1374/1375, train_loss: 8.90948975051171e-06, t_sample_acc: 0.3076783114992722,lr: 1.6313393930156295e-11, batch_time: 1.7615888118743896, total_time: 2462.4932713508606 ---------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 14/20, batch: 1375/1375, train_loss: 8.915239660960982e-06, t_sample_acc: 0.3076969697041945,lr: 5e-05, batch_time: 0.885399580001831, total_time: 2463.402421236038 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:35<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/20, val_sample_acc: 0.325, val_rel_prec: 0.7991246256622714, val_rel_rec: 0.8052460538532775, val_rel_f1: 0.8021736616449757,\n",
      "val_time: 95.6311240196228\n",
      "Current avf_f1: 0.8021736616449757, Best f1: 0.8021736616449757\n",
      "Epoch: 15/20, batch: 1374/1375, train_loss: 8.678583629915982e-06, t_sample_acc: 0.3056768558951965,lr: 2.5028559927002325e-05, batch_time: 1.7650160789489746, total_time: 2462.0267374515533 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 15/20, batch: 1375/1375, train_loss: 8.684439946591737e-06, t_sample_acc: 0.3054545454545455,lr: 2.5000000000000008e-05, batch_time: 0.8861005306243896, total_time: 2462.927896499634 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:35<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/20, val_sample_acc: 0.359, val_rel_prec: 0.8442755125546915, val_rel_rec: 0.8173505798394108, val_rel_f1: 0.8305949007998528,\n",
      "val_time: 95.3206787109375\n",
      "Current avf_f1: 0.8305949007998528, Best f1: 0.8305949007998528\n",
      "Epoch: 16/20, batch: 1374/1375, train_loss: 6.343265523323078e-06, t_sample_acc: 0.43649927219796214,lr: 1.6313393930156295e-11, batch_time: 1.7650213241577148, total_time: 2470.6102521419525 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 16/20, batch: 1375/1375, train_loss: 6.341546696272747e-06, t_sample_acc: 0.4364242424314672,lr: 5e-05, batch_time: 0.8841009140014648, total_time: 2471.508337497711 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:39<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/20, val_sample_acc: 0.4205, val_rel_prec: 0.86708131766872, val_rel_rec: 0.8386809269162023, val_rel_f1: 0.8526446935732814,\n",
      "val_time: 99.67811155319214\n",
      "Current avf_f1: 0.8526446935732814, Best f1: 0.8526446935732814\n",
      "Epoch: 17/20, batch: 1374/1375, train_loss: 6.4506647034652365e-06, t_sample_acc: 0.3988355167394469,lr: 2.5028559927002325e-05, batch_time: 1.7578082084655762, total_time: 2499.0904314517975 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 17/20, batch: 1375/1375, train_loss: 6.450740577913001e-06, t_sample_acc: 0.39854545454545454,lr: 2.5000000000000008e-05, batch_time: 0.8813259601593018, total_time: 2499.9938719272614 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:41<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/20, val_sample_acc: 0.4595, val_rel_prec: 0.8762957843814587, val_rel_rec: 0.8554081403192971, val_rel_f1: 0.8657259899363325,\n",
      "val_time: 101.31661486625671\n",
      "Current avf_f1: 0.8657259899363325, Best f1: 0.8657259899363325\n",
      "Epoch: 18/20, batch: 1374/1375, train_loss: 4.755216707425484e-06, t_sample_acc: 0.5264737991266376,lr: 1.6313393930156295e-11, batch_time: 1.7613909244537354, total_time: 2506.2628321647644 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 18/20, batch: 1375/1375, train_loss: 4.7543773016514025e-06, t_sample_acc: 0.5265757575902071,lr: 5e-05, batch_time: 0.8829264640808105, total_time: 2507.1632475852966 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:44<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/20, val_sample_acc: 0.4875, val_rel_prec: 0.8977194194885764, val_rel_rec: 0.8631229235880208, val_rel_f1: 0.8800813007630075,\n",
      "val_time: 104.19761347770691\n",
      "Current avf_f1: 0.8800813007630075, Best f1: 0.8800813007630075\n",
      "Epoch: 19/20, batch: 1374/1375, train_loss: 5.03668416756983e-06, t_sample_acc: 0.48034934497816595,lr: 2.5028559927002325e-05, batch_time: 1.7640719413757324, total_time: 2472.086092710495 ----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 19/20, batch: 1375/1375, train_loss: 5.0350387408054136e-06, t_sample_acc: 0.4804848484992981,lr: 2.5000000000000008e-05, batch_time: 0.8874900341033936, total_time: 2472.99281001091 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:34<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/20, val_sample_acc: 0.5015, val_rel_prec: 0.8958765261460286, val_rel_rec: 0.8766907123534519, val_rel_f1: 0.886179788032474,\n",
      "val_time: 94.96892619132996\n",
      "Current avf_f1: 0.886179788032474, Best f1: 0.886179788032474\n",
      "Epoch: 20/20, batch: 1374/1375, train_loss: 3.752542988107898e-06, t_sample_acc: 0.5953420669577875,lr: 1.6313393930156295e-11, batch_time: 1.760580062866211, total_time: 2460.476558446884 ----------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Validating:   0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 20/20, batch: 1375/1375, train_loss: 3.7528164102282478e-06, t_sample_acc: 0.595393939408389,lr: 5e-05, batch_time: 0.8824944496154785, total_time: 2461.3783543109894 -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 250/250 [01:34<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/20, val_sample_acc: 0.537, val_rel_prec: 0.9129232895645955, val_rel_rec: 0.8816462736373553, val_rel_f1: 0.89701222267521,\n",
      "val_time: 94.56996297836304\n",
      "Current avf_f1: 0.89701222267521, Best f1: 0.89701222267521\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 20\n",
    "# load the last best state (if any)\n",
    "model_all_state_paths = glob.glob(model_state_dict_dir + \"/*.pt\")\n",
    "if len(model_all_state_paths) > 0:\n",
    "    model_last_state_path = get_last_state_path(model_state_dict_dir)\n",
    "    scheduler_last_state_path = get_last_state_path(schedule_state_dict_dir)\n",
    "    \n",
    "    rel_extractor.load_state_dict(torch.load(model_last_state_path))\n",
    "    print(\"------------model state {} loaded ----------------\".format(model_last_state_path.split(\"/\")[-1]))\n",
    "    scheduler.load_state_dict(torch.load(scheduler_last_state_path))\n",
    "    print(\"------------scheduler state {} loaded ----------------\".format(scheduler_last_state_path.split(\"/\")[-1]))\n",
    "\n",
    "train_n_valid(train_dataloader, dev_dataloader, optimizer, scheduler, epoch_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (machine_learning)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
