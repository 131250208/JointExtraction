{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from IPython.core.debugger import set_trace\n",
    "from pprint import pprint\n",
    "import unicodedata\n",
    "from transformers import AutoModel, BasicTokenizer, BertTokenizerFast\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import time\n",
    "from layers import LayerNorm\n",
    "import logging\n",
    "from utils import Preprocessor, HandshakingTaggingScheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0 will be used\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device {} will be used\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_home = \"/data/yubowen/experiments/relextr/pretrained_model\"\n",
    "project_root = \"/data/yubowen/experiments/relextr\"\n",
    "data_home = os.path.join(project_root, \"data\")\n",
    "\n",
    "experiment_dir = os.path.join(project_root, \"exp\")\n",
    "experiment_name = \"nyt\"\n",
    "model_state_dict_dir = os.path.join(project_root, experiment_dir, experiment_name, \"model_state_dict\")\n",
    "schedule_state_dict_dir = os.path.join(project_root, experiment_dir, experiment_name, \"schedule_state_dict\")\n",
    "\n",
    "\n",
    "if not os.path.exists(model_state_dict_dir):\n",
    "    os.makedirs(model_state_dict_dir)\n",
    "if not os.path.exists(schedule_state_dict_dir):\n",
    "    os.makedirs(schedule_state_dict_dir)\n",
    "    \n",
    "nyt_data_dir = os.path.join(data_home, \"nyt\")\n",
    "nyt_train_data_path = os.path.join(nyt_data_dir, \"raw_train.json\")\n",
    "nyt_valid_data_path = os.path.join(nyt_data_dir, \"raw_valid.json\")\n",
    "nyt_test_data_path = os.path.join(nyt_data_dir, \"raw_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    '%(asctime)s - %(name)s - %(levelname)s: - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# 使用FileHandler输出到文件\n",
    "fh = logging.FileHandler('log.txt')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "# 使用StreamHandler输出到屏幕\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# 添加两个Handler\n",
    "logger.addHandler(ch)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 24\n",
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(path, \"r\", encoding = \"utf-8\") as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_train_data = get_data(nyt_train_data_path)\n",
    "nyt_valid_data = get_data(nyt_valid_data_path)\n",
    "nyt_test_data = get_data(nyt_test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_train_data = nyt_train_data[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stress_mark(text):\n",
    "    text = \"\".join([c for c in unicodedata.normalize(\"NFD\", text) if unicodedata.category(c) != \"Mn\"])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10200it [00:00, 42754.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for ind, sample in tqdm(enumerate(nyt_train_data + nyt_valid_data + nyt_test_data)):\n",
    "    # add id\n",
    "    sample[\"id\"] = ind\n",
    "    # remove 重音符号\n",
    "    for rel in sample[\"relationMentions\"]:\n",
    "        rel[\"em1Text\"] = remove_stress_mark(rel[\"em1Text\"])\n",
    "        rel[\"em2Text\"] = remove_stress_mark(rel[\"em2Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10200/10200 [00:00<00:00, 567188.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# fix bad sample\n",
    "for sample in tqdm(nyt_train_data + nyt_valid_data + nyt_test_data):\n",
    "    if \"XXXXXXXXXX\" in sample[\"sentText\"]:\n",
    "        sample[\"sentText\"] = re.sub(\"X+\", \"\", sample[\"sentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - Model name '/data/yubowen/experiments/relextr/pretrained_model/bert-base-cased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/data/yubowen/experiments/relextr/pretrained_model/bert-base-cased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - Didn't find file /data/yubowen/experiments/relextr/pretrained_model/bert-base-cased/added_tokens.json. We won't load it.\n",
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - Didn't find file /data/yubowen/experiments/relextr/pretrained_model/bert-base-cased/special_tokens_map.json. We won't load it.\n",
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - Didn't find file /data/yubowen/experiments/relextr/pretrained_model/bert-base-cased/tokenizer_config.json. We won't load it.\n",
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - loading file /data/yubowen/experiments/relextr/pretrained_model/bert-base-cased/vocab.txt\n",
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - loading file None\n",
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - loading file None\n",
      "2020-05-30 18:12:36 - transformers.tokenization_utils - INFO: - loading file None\n"
     ]
    }
   ],
   "source": [
    "# bert tokenizer\n",
    "pretrained_model_home = \"/data/yubowen/experiments/relextr/pretrained_model\"\n",
    "model_path = os.path.join(pretrained_model_home, \"bert-base-cased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path, add_special_tokens = False, do_lower_case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "def get_tok2char_span_map(text):\n",
    "    return tokenizer.encode_plus(text, \n",
    "                               return_offsets_mapping = True, \n",
    "                               add_special_tokens = False)[\"offset_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "# transform\n",
    "def tran2normal_samples(data):\n",
    "    normal_sample_list = []\n",
    "    for sample in tqdm(data):\n",
    "        normal_sample = {\n",
    "            \"text\": sample[\"sentText\"],\n",
    "            \"id\": sample[\"id\"],\n",
    "        }\n",
    "        normal_rel_list = []\n",
    "        for rel in sample[\"relationMentions\"]:\n",
    "            normal_rel_list.append({\n",
    "                \"subject\": rel[\"em1Text\"],\n",
    "                \"object\": rel[\"em2Text\"],\n",
    "                \"predicate\": rel[\"label\"],\n",
    "            })\n",
    "        normal_sample[\"relation_list\"] = normal_rel_list\n",
    "        normal_sample_list.append(normal_sample)\n",
    "    return normal_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 234646.38it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 70498.43it/s]\n",
      "Adding token level spans: 100%|██████████| 200/200 [00:00<00:00, 1241.50it/s]\n",
      "5000it [00:00, 454706.53it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 114024.61it/s]\n",
      "Adding token level spans: 100%|██████████| 5000/5000 [00:03<00:00, 1311.25it/s]\n",
      "5000it [00:00, 127309.99it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 65875.26it/s]\n",
      "Adding token level spans: 100%|██████████| 5000/5000 [00:04<00:00, 1241.56it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor(transform_func = tran2normal_samples, \n",
    "                            get_tok2char_span_map_func = get_tok2char_span_map)\n",
    "train_data = preprocessor.get_normal_dataset(nyt_train_data, add_id = True, dataset_name = \"train\")\n",
    "valid_data = preprocessor.get_normal_dataset(nyt_valid_data, add_id = True, dataset_name = \"valid\")\n",
    "test_data = preprocessor.get_normal_dataset(nyt_test_data, add_id = True, dataset_name = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Massachusetts ASTON MAGNA Great Barrington ; also at Bard College , Annandale-on-Hudson , N.Y. , July 1-Aug .',\n",
       " 'id': 'train_0',\n",
       " 'relation_list': [{'subject': 'Annandale-on-Hudson',\n",
       "   'object': 'Bard College',\n",
       "   'subj_span': (17, 24),\n",
       "   'obj_span': (13, 16),\n",
       "   'predicate': '/location/location/contains'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check token level span\n",
    "# def extr_ent(text, tok_span, tok2char_span):\n",
    "#     char_span_list = tok2char_span[tok_span[0]:tok_span[1]]\n",
    "#     char_span = (char_span_list[0][0], char_span_list[-1][1])\n",
    "#     decoded_ent = text[char_span[0]:char_span[1]]\n",
    "#     return decoded_ent\n",
    "\n",
    "# for sample in tqdm(train_data + valid_data + test_data):\n",
    "#     text = sample[\"text\"]\n",
    "#     tok2char_span = get_tok2char_span_map(text)\n",
    "#     for rel in sample[\"relation_list\"]:\n",
    "#         subj_span, obj_span = rel[\"subj_span\"], rel[\"obj_span\"]\n",
    "#         assert extr_ent(text, subj_span, tok2char_span) == rel[\"subject\"] and extr_ent(text, obj_span, tok2char_span) == rel[\"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_short_samples(sample_list, sliding_len = 50):\n",
    "    new_sample_list = []\n",
    "    for sample in tqdm(sample_list, desc = \"Splitting\"):\n",
    "        text_id = sample[\"id\"]\n",
    "        text = sample[\"text\"]\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        offset_map = tokenizer.encode_plus(text, return_offsets_mapping = True, \n",
    "                                           add_special_tokens = False)[\"offset_mapping\"]\n",
    "        \n",
    "        # sliding on token level\n",
    "        split_sample_list = []\n",
    "        for start_ind in range(0, len(tokens), sliding_len):\n",
    "            while \"##\" in tokens[start_ind]:\n",
    "                start_ind -= 1\n",
    "            end_ind = start_ind + max_seq_len\n",
    "#             while \"##\" in tokens[end_ind]:\n",
    "#                 end_ind += 1\n",
    "            char_span_list = offset_map[start_ind:end_ind]\n",
    "            char_level_span = (char_span_list[0][0], char_span_list[-1][1])\n",
    "            sub_text = text[char_level_span[0]:char_level_span[1]]\n",
    "\n",
    "            new_sample = {\n",
    "                \"id\": text_id,\n",
    "                \"text\": sub_text,\n",
    "                \"relation_list\": []\n",
    "            }\n",
    "            for rel in sample[\"relation_list\"]:\n",
    "                subj_span = rel[\"subj_span\"]\n",
    "                obj_span = rel[\"obj_span\"]\n",
    "                if subj_span[0] >= start_ind and subj_span[1] <= end_ind \\\n",
    "                    and obj_span[0] >= start_ind and obj_span[1] <= end_ind:\n",
    "                    new_rel = copy.deepcopy(rel)\n",
    "                    new_rel[\"subj_span\"] = (subj_span[0] - start_ind, subj_span[1] - start_ind)\n",
    "                    new_rel[\"obj_span\"] = (obj_span[0] - start_ind, obj_span[1] - start_ind)\n",
    "                    new_sample[\"relation_list\"].append(new_rel)\n",
    "#                 else:\n",
    "#                     set_trace()\n",
    "            if len(new_sample[\"relation_list\"]) > 0:\n",
    "                split_sample_list.append(new_sample)\n",
    "        if len(split_sample_list) == 0:\n",
    "            set_trace()\n",
    "        new_sample_list.extend(split_sample_list)\n",
    "    return new_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting: 100%|██████████| 200/200 [00:00<00:00, 1506.50it/s]\n",
      "Splitting: 100%|██████████| 5000/5000 [00:03<00:00, 1557.66it/s]\n",
      "Splitting: 100%|██████████| 5000/5000 [00:03<00:00, 1584.01it/s]\n"
     ]
    }
   ],
   "source": [
    "short_train_data = split_into_short_samples(train_data)\n",
    "short_valid_data = split_into_short_samples(valid_data)\n",
    "short_test_data = split_into_short_samples(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 5197 5185\n"
     ]
    }
   ],
   "source": [
    "print(len(short_train_data), len(short_valid_data), len(short_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10200/10200 [00:00<00:00, 303952.35it/s]\n"
     ]
    }
   ],
   "source": [
    "rel_set = set()\n",
    "for sample in tqdm(train_data + valid_data + test_data):\n",
    "    for rel in sample[\"relation_list\"]:\n",
    "        rel_set.add(rel[\"predicate\"])\n",
    "rel_set = sorted(rel_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel2id = {rel:ind for ind, rel in enumerate(rel_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "handshaking_tagger = HandshakingTaggingScheme(rel2id = rel2id, max_seq_len = max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_to(sample1, sample2):\n",
    "    assert sample1[\"id\"] == sample2[\"id\"]\n",
    "    assert sample1[\"text\"] == sample2[\"text\"]\n",
    "    memory_set = set()\n",
    "    for rel in sample2[\"relation_list\"]:\n",
    "        memory = \"{}\\u2E80{}\\u2E80{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], \n",
    "                                                             rel[\"predicate\"], \n",
    "                                                             rel[\"object\"], \n",
    "                                                             str(rel[\"subj_span\"]), \n",
    "                                                             str(rel[\"obj_span\"]))\n",
    "        memory_set.add(memory)\n",
    "    for rel in sample1[\"relation_list\"]:\n",
    "        memory = \"{}\\u2E80{}\\u2E80{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], \n",
    "                                                             rel[\"predicate\"], \n",
    "                                                             rel[\"object\"], \n",
    "                                                             str(rel[\"subj_span\"]), \n",
    "                                                             str(rel[\"obj_span\"]))\n",
    "        if memory not in memory_set:\n",
    "            set_trace()\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = train_data[1000]\n",
    "# ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = handshaking_tagger.get_spots(sample)\n",
    "\n",
    "# ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag(ent_matrix_spots)\n",
    "# head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(head_rel_matrix_spots)\n",
    "# tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(tail_rel_matrix_spots)\n",
    "# # %timeit spots2shaking_tag(ent_matrix_spots)\n",
    "# text = sample[\"text\"]\n",
    "# tok2char_span_map = get_tok2char_span_map(text)\n",
    "# decoded_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "#                                              ent_shaking_tag, \n",
    "#                                              head_rel_shaking_tag, \n",
    "#                                              tail_rel_shaking_tag, \n",
    "#                                              tok2char_span_map)\n",
    "# # %timeit decode_rel_fr_shaking_tag(text, ent_shaking_tag, head_rel_shaking_tag, tail_rel_shaking_tag, offset_map)\n",
    "# pred_sample = {\n",
    "#     \"id\": sample[\"id\"],\n",
    "#     \"text\": text,\n",
    "#     \"relation_list\": decoded_rel_list,\n",
    "# }\n",
    "# sample_equal_to(pred_sample, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for sample in tqdm(train_data + valid_data + test_data):\n",
    "#     ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = handshaking_tagger.get_spots(sample)\n",
    "\n",
    "#     ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag(ent_matrix_spots)\n",
    "#     head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(head_rel_matrix_spots)\n",
    "#     tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag(tail_rel_matrix_spots)\n",
    "#     # %timeit spots2shaking_tag(ent_matrix_spots)\n",
    "#     text = sample[\"text\"]\n",
    "#     tok2char_span_map = get_tok2char_span_map(text)\n",
    "#     decoded_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "#                                                  ent_shaking_tag, \n",
    "#                                                  head_rel_shaking_tag, \n",
    "#                                                  tail_rel_shaking_tag, \n",
    "#                                                  tok2char_span_map)\n",
    "#     # %timeit decode_rel_fr_shaking_tag(text, ent_shaking_tag, head_rel_shaking_tag, tail_rel_shaking_tag, offset_map)\n",
    "#     pred_sample = {\n",
    "#         \"id\": sample[\"id\"],\n",
    "#         \"text\": text,\n",
    "#         \"relation_list\": decoded_rel_list,\n",
    "#     }\n",
    "#     if not sample_equal_to(pred_sample, sample) or not sample_equal_to(pred_sample, sample):\n",
    "# #         set_trace()\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check batch tagging and decoding\n",
    "# batch_samples = train_data[:100]\n",
    "# batch_ent_spots, batch_head_rel_spots, batch_tail_rel_spots = [], [], []\n",
    "# for sample in tqdm(batch_samples):\n",
    "#     ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = handshaking_tagger.get_spots(sample)\n",
    "#     batch_ent_spots.append(ent_matrix_spots)\n",
    "#     batch_head_rel_spots.append(head_rel_matrix_spots)\n",
    "#     batch_tail_rel_spots.append(tail_rel_matrix_spots)\n",
    "# batch_ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag4batch(batch_ent_spots)\n",
    "# batch_head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(batch_head_rel_spots)\n",
    "# batch_tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(batch_tail_rel_spots)\n",
    "\n",
    "# for ind, sample in tqdm(enumerate(batch_samples)):\n",
    "#     text = sample[\"text\"]\n",
    "#     tok2char_span = get_tok2char_span_map(text)\n",
    "#     ent_shaking_tag = batch_ent_shaking_tag[ind]\n",
    "#     head_rel_shaking_tag = batch_head_rel_shaking_tag[ind]\n",
    "#     tail_rel_shaking_tag = batch_tail_rel_shaking_tag[ind]\n",
    "#     decoded_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "#                                                                      ent_shaking_tag,\n",
    "#                                                                      head_rel_shaking_tag,\n",
    "#                                                                      tail_rel_shaking_tag,\n",
    "#                                                                      tok2char_span)\n",
    "#     pred_sample = {\n",
    "#         \"id\": sample[\"id\"],\n",
    "#         \"text\": text,\n",
    "#         \"relation_list\": decoded_rel_list,\n",
    "#     }\n",
    "#     if not sample_equal_to(pred_sample, sample):\n",
    "#         set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "def get_indexed_train_valid_data(data):\n",
    "    indexed_samples = []\n",
    "    for ind, sample in tqdm(enumerate(data), desc = \"Generate indexed train or valid data\"):\n",
    "        text = sample[\"text\"]\n",
    "        text_id = sample[\"id\"]\n",
    "        # codes for bert input\n",
    "        # @specific\n",
    "        codes = tokenizer.encode_plus(text, \n",
    "                                    return_offsets_mapping = True, \n",
    "                                    add_special_tokens = False,\n",
    "                                    max_length = max_seq_len, \n",
    "                                    pad_to_max_length = True)\n",
    "        \n",
    "        \n",
    "        # tagging\n",
    "        spots_tuple = handshaking_tagger.get_spots(sample)\n",
    "        \n",
    "        # get codes\n",
    "        # @specific\n",
    "        input_ids = torch.tensor(codes[\"input_ids\"]).long()\n",
    "        attention_mask = torch.tensor(codes[\"attention_mask\"]).long()\n",
    "        token_type_ids = torch.tensor(codes[\"token_type_ids\"]).long()\n",
    "        offset_map = codes[\"offset_mapping\"]\n",
    "\n",
    "        sample_tp = (text_id,\n",
    "                     text, \n",
    "                     input_ids,\n",
    "                     attention_mask,\n",
    "                     token_type_ids,\n",
    "                     offset_map,\n",
    "                     spots_tuple,\n",
    "                    )\n",
    "        indexed_samples.append(sample_tp)       \n",
    "    return indexed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @specific\n",
    "def get_indexed_pred_data(data):\n",
    "    indexed_samples = []\n",
    "    for ind, sample in tqdm(enumerate(data), desc = \"Generate indexed pred data\"):\n",
    "        text = sample[\"text\"] \n",
    "        text_id = sample[\"id\"]\n",
    "        # @specific\n",
    "        codes = tokenizer.encode_plus(text, \n",
    "                                    return_offsets_mapping = True, \n",
    "                                    add_special_tokens = False,\n",
    "                                    max_length = max_seq_len, \n",
    "                                    pad_to_max_length = True)\n",
    "        \n",
    "        input_ids = torch.tensor(codes[\"input_ids\"]).long()\n",
    "        attention_mask = torch.tensor(codes[\"attention_mask\"]).long()\n",
    "        token_type_ids = torch.tensor(codes[\"token_type_ids\"]).long()\n",
    "        offset_map = codes[\"offset_mapping\"]\n",
    "\n",
    "        sample_tp = (text_id,\n",
    "                     text, \n",
    "                     input_ids,\n",
    "                     attention_mask,\n",
    "                     token_type_ids,\n",
    "                     offset_map,\n",
    "                     )\n",
    "        indexed_samples.append(sample_tp)       \n",
    "    return indexed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_dev_batch(batch_data):\n",
    "    text_id_list = []\n",
    "    text_list = []\n",
    "    input_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    token_type_ids_list = [] \n",
    "    offset_map_list = []\n",
    "    ent_spots_list = []\n",
    "    head_rel_spots_list = []\n",
    "    tail_rel_spots_list = []\n",
    "    \n",
    "    for sample in batch_data:\n",
    "        text_id_list.append(sample[0])\n",
    "        text_list.append(sample[1])\n",
    "        input_ids_list.append(sample[2])\n",
    "        attention_mask_list.append(sample[3])        \n",
    "        token_type_ids_list.append(sample[4])        \n",
    "        offset_map_list.append(sample[5])\n",
    "        \n",
    "        ent_matrix_spots, head_rel_matrix_spots, tail_rel_matrix_spots = sample[6]\n",
    "        ent_spots_list.append(ent_matrix_spots)\n",
    "        head_rel_spots_list.append(head_rel_matrix_spots)\n",
    "        tail_rel_spots_list.append(tail_rel_matrix_spots)\n",
    "    \n",
    "    # @specific: codes indexed by bert tokenizer\n",
    "    batch_input_ids = torch.stack(input_ids_list, dim = 0)\n",
    "    batch_attention_mask = torch.stack(attention_mask_list, dim = 0)\n",
    "    batch_token_type_ids = torch.stack(token_type_ids_list, dim = 0)\n",
    "    \n",
    "#     t1 = time.time()\n",
    "    batch_ent_shaking_tag = handshaking_tagger.sharing_spots2shaking_tag4batch(ent_spots_list)\n",
    "    batch_head_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(head_rel_spots_list)\n",
    "    batch_tail_rel_shaking_tag = handshaking_tagger.spots2shaking_tag4batch(tail_rel_spots_list)\n",
    "#     print(time.time() - t1)\n",
    "    return text_id_list, text_list, batch_input_ids, batch_attention_mask, batch_token_type_ids, offset_map_list, batch_ent_shaking_tag, batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pred_batch(batch_data):\n",
    "    text_ids = []\n",
    "    text_list = []\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    token_type_ids = [] \n",
    "    offset_map = []\n",
    "    for sample in batch_data:\n",
    "        text_ids.append(sample[0])\n",
    "        text_list.append(sample[1])\n",
    "        input_ids.append(sample[2])\n",
    "        attention_mask.append(sample[3])        \n",
    "        token_type_ids.append(sample[4])        \n",
    "        offset_map.append(sample[5])\n",
    "    input_ids = torch.stack(input_ids, dim = 0)\n",
    "    attention_mask = torch.stack(attention_mask, dim = 0)\n",
    "    token_type_ids = torch.stack(token_type_ids, dim = 0)\n",
    "    return text_ids, text_list, input_ids, attention_mask, token_type_ids, offset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @uni\n",
    "def get_train_dev_dataloader_gen(indexed_train_sample_list, indexed_dev_sample_list, batch_size):\n",
    "    train_dataloader = DataLoader(MyDataset(indexed_train_sample_list), \n",
    "                                      batch_size = batch_size, \n",
    "                                      shuffle = True, \n",
    "                                      num_workers = 6,\n",
    "                                      drop_last = False,\n",
    "                                      collate_fn = generate_train_dev_batch,\n",
    "                                     )\n",
    "    dev_dataloader = DataLoader(MyDataset(indexed_dev_sample_list), \n",
    "                              batch_size = batch_size, \n",
    "                              shuffle = True, \n",
    "                              num_workers = 6,\n",
    "                              drop_last = False,\n",
    "                              collate_fn = generate_train_dev_batch,\n",
    "                             )\n",
    "    return train_dataloader, dev_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 213it [00:00, 1235.24it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_train_data = get_indexed_train_valid_data(short_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 5197it [00:03, 1492.38it/s]\n"
     ]
    }
   ],
   "source": [
    "indexed_valid_data = get_indexed_train_valid_data(short_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at dataloader\n",
    "train_dataloader, dev_dataloader = get_train_dev_dataloader_gen(indexed_train_data, indexed_valid_data, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test data loading time\n",
    "\n",
    "# # 0 workers: 40, 41\n",
    "# # 3 workers: 28\n",
    "# # 4 workers: 23\n",
    "# # 5 workers: 19\n",
    "# # 6 workers: 16, \n",
    "# # 7 workers: 22, 28, 21\n",
    "# # 10 wokers: 27, 28, \n",
    "# for ep in range(100):\n",
    "#     t1 = time.time()\n",
    "#     for ind, batch_data in enumerate(dev_dataloader):\n",
    "#         print(\"\\r{}/{}\".format(ind + 1, len(dev_dataloader)), end = \"\")\n",
    "#     print(\"ep {}: {}\".format(ep + 1, time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_iter = iter(train_dataloader)\n",
    "# %timeit next(train_data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virginia , near the Rappahannock River .\n",
      "\n",
      "Virginia, near the Rappahannock River. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "32\n",
      "torch.Size([32, 8256])\n",
      "torch.Size([32, 24, 8256])\n",
      "torch.Size([32, 24, 8256])\n"
     ]
    }
   ],
   "source": [
    "train_data_iter = iter(train_dataloader)\n",
    "batch_data = next(train_data_iter)\n",
    "text_id_list, text_list, batch_input_ids, \\\n",
    "batch_attention_mask, batch_token_type_ids, \\\n",
    "offset_map_list, batch_ent_shaking_tag, \\\n",
    "batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_data\n",
    "\n",
    "print(text_list[0])\n",
    "print()\n",
    "print(tokenizer.decode(batch_input_ids[0].tolist()))\n",
    "print(batch_input_ids.size())\n",
    "print(batch_attention_mask.size())\n",
    "print(batch_token_type_ids.size())\n",
    "print(len(offset_map_list))\n",
    "print(batch_ent_shaking_tag.size())\n",
    "print(batch_head_rel_shaking_tag.size())\n",
    "print(batch_tail_rel_shaking_tag.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelExtractor(nn.Module):\n",
    "    def __init__(self, encoder, rel_size):\n",
    "        super().__init__()\n",
    "        # @specific\n",
    "        self.encoder = encoder\n",
    "        hidden_size = encoder.config.hidden_size\n",
    "\n",
    "        self.ent_fc = nn.Linear(hidden_size, 2)\n",
    "        self.head_rel_fc_list = [nn.Linear(hidden_size, 3) for _ in range(rel_size)]\n",
    "        self.tail_rel_fc_list = [nn.Linear(hidden_size, 3) for _ in range(rel_size)]\n",
    "        \n",
    "        # register fcs\n",
    "#         for ind, fc in enumerate(self.ent_fc_list):\n",
    "#             self.register_parameter(\"weight_4_ent_in_rel{}\".format(ind), fc.weight)\n",
    "#             self.register_parameter(\"bias_4_ent_in_rel{}\".format(ind), fc.bias)\n",
    "        for ind, fc in enumerate(self.head_rel_fc_list):\n",
    "            self.register_parameter(\"weight_4_head_rel{}\".format(ind), fc.weight)\n",
    "            self.register_parameter(\"bias_4_head_rel{}\".format(ind), fc.bias)\n",
    "        for ind, fc in enumerate(self.tail_rel_fc_list):\n",
    "            self.register_parameter(\"weight_4_tail_rel{}\".format(ind), fc.weight)\n",
    "            self.register_parameter(\"bias_4_tail_rel{}\".format(ind), fc.bias)\n",
    "            \n",
    "        # conditional layer normaliztion\n",
    "        fake_inputs = torch.zeros([batch_size, max_seq_len, hidden_size])\n",
    "        self.cond_layer_norm = LayerNorm(fake_inputs.size(), hidden_size, conditional = True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # @specific\n",
    "        # input_ids, attention_mask, token_type_ids: (batch_size, seq_len)\n",
    "        context_outputs = self.encoder(input_ids, attention_mask, token_type_ids)\n",
    "        # last_hidden_state: (batch_size, seq_len, hidden_size)\n",
    "        last_hidden_state = context_outputs[0]\n",
    "        \n",
    "        # shaking_hiddens: (batch_size, 1 + ... + seq_len, hidden_size)\n",
    "        shaking_hiddens = self.shake_hands_afterwards(last_hidden_state)\n",
    "        \n",
    "        ent_shaking_outputs = self.ent_fc(shaking_hiddens)\n",
    "            \n",
    "        head_rel_shaking_outputs_list = []\n",
    "        for fc in self.head_rel_fc_list:\n",
    "            head_rel_shaking_outputs_list.append(fc(shaking_hiddens))\n",
    "            \n",
    "        tail_rel_shaking_outputs_list = []\n",
    "        for fc in self.tail_rel_fc_list:\n",
    "            tail_rel_shaking_outputs_list.append(fc(shaking_hiddens))\n",
    "        \n",
    "        head_rel_shaking_outputs = torch.stack(head_rel_shaking_outputs_list, dim = 1)\n",
    "        tail_rel_shaking_outputs = torch.stack(tail_rel_shaking_outputs_list, dim = 1)\n",
    "        \n",
    "        return ent_shaking_outputs, head_rel_shaking_outputs, tail_rel_shaking_outputs\n",
    "\n",
    "    def shake_hands_afterwards(self, seq_hiddens):\n",
    "        '''\n",
    "        seq_hiddens: (batch_size, seq_len, hidden_size) (32, 3, 5)\n",
    "        return shake_hands_matrix_hiddens: (batch_size, (1 + seq_len) * seq_len / 2, hidden_size) (32, 5+4+3+2+1, 5)\n",
    "        '''\n",
    "        seq_len = seq_hiddens.size()[-2]\n",
    "        shake_hands_hidden_list = []\n",
    "        for ind in range(seq_len):\n",
    "            hidden_each_step = seq_hiddens[:, ind, :]\n",
    "            # seq_len - ind: only shake afterwards\n",
    "            repeat_hidden_each_step = hidden_each_step[:, None, :].repeat(1, seq_len - ind, 1) \n",
    "    #         shake_hands_hidden = torch.cat([repeat_hidden_each_step, seq_hiddens[:, ind:, :]], dim = -1)\n",
    "            shake_hands_hidden = self.cond_layer_norm(seq_hiddens[:, ind:, :], repeat_hidden_each_step)\n",
    "            shake_hands_hidden_list.append(shake_hands_hidden)\n",
    "        shake_hands_matrix_hiddens = torch.cat(shake_hands_hidden_list, dim = 1)\n",
    "        return shake_hands_matrix_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-29 15:31:13 - transformers.configuration_utils - INFO: - loading configuration file /data/yubowen/experiments/relextr/pretrained_model/bert-base-cased/config.json\n",
      "2020-05-29 15:31:13 - transformers.configuration_utils - INFO: - Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "2020-05-29 15:31:13 - transformers.modeling_utils - INFO: - loading weights file /data/yubowen/experiments/relextr/pretrained_model/bert-base-cased/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "roberta = AutoModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_extractor = RelExtractor(roberta, len(rel2id))\n",
    "rel_extractor = rel_extractor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test model\n",
    "# batch_input_ids, \\\n",
    "# batch_attention_mask,\\\n",
    "# batch_token_type_ids = batch_input_ids.to(device), \\\n",
    "#                          batch_attention_mask.to(device), \\\n",
    "#                          batch_token_type_ids.to(device)\n",
    "# with torch.no_grad():                 \n",
    "#     ent_shaking_outputs, \\\n",
    "#     head_rel_shaking_outputs, \\\n",
    "#     tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "#                                               batch_attention_mask, \n",
    "#                                               batch_token_type_ids)\n",
    "\n",
    "# print(ent_shaking_outputs.size())\n",
    "# print(head_rel_shaking_outputs.size())\n",
    "# print(tail_rel_shaking_outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_loss(weights = None):\n",
    "    if weights is not None:\n",
    "        weights = torch.FloatTensor(weights).to(device)\n",
    "    cross_en = nn.CrossEntropyLoss(weight = weights)  \n",
    "    return lambda pred, target: cross_en(pred.view(-1, pred.size()[-1]), target.view(-1))\n",
    "loss_func = bias_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_accuracy(pred, truth):\n",
    "    '''\n",
    "    计算所有抽取字段都正确的样本比例\n",
    "    即该batch的输出与truth全等的样本比例\n",
    "    '''\n",
    "    # (batch_size, ..., seq_len, tag_size) -> (batch_size, ..., seq_len)\n",
    "    pred_id = torch.argmax(pred, dim = -1)\n",
    "    # (batch_size, ..., seq_len) -> (batch_size, )，把每个sample压成一条seq\n",
    "    pred_id = pred_id.view(pred_id.size()[0], -1)\n",
    "    truth = truth.view(truth.size()[0], -1)\n",
    "    \n",
    "    # (batch_size, )，每个元素是pred与truth之间tag相同的数量\n",
    "    correct_tag_num = torch.sum(torch.eq(truth, pred_id).float(), dim = 1)\n",
    "\n",
    "    # seq维上所有tag必须正确，所以correct_tag_num必须等于seq的长度才算一个correct的sample\n",
    "    sample_acc_ = torch.eq(correct_tag_num, torch.ones_like(correct_tag_num) * truth.size()[-1]).float()\n",
    "    sample_acc = torch.mean(sample_acc_)\n",
    "    \n",
    "    return sample_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_cpg(text_list, offset_map_list, \n",
    "                 batch_pred_ent_shaking_outputs,\n",
    "                 batch_pred_head_rel_shaking_outputs,\n",
    "                 batch_pred_tail_rel_shaking_outputs,\n",
    "                 batch_gold_ent_shaking_tag,\n",
    "                 batch_gold_head_rel_shaking_tag,\n",
    "                 batch_gold_tail_rel_shaking_tag):\n",
    "    batch_pred_ent_shaking_tag = torch.argmax(batch_pred_ent_shaking_outputs, dim = -1)\n",
    "    batch_pred_head_rel_shaking_tag = torch.argmax(batch_pred_head_rel_shaking_outputs, dim = -1)\n",
    "    batch_pred_tail_rel_shaking_tag = torch.argmax(batch_pred_tail_rel_shaking_outputs, dim = -1)\n",
    "    \n",
    "    correct_num, pred_num, gold_num = 0, 0, 0\n",
    "    for ind in range(len(text_list)):\n",
    "        text = text_list[ind]\n",
    "        offset_map = offset_map_list[ind]\n",
    "        gold_ent_shaking_tag, pred_ent_shaking_tag = batch_gold_ent_shaking_tag[ind], batch_pred_ent_shaking_tag[ind]\n",
    "        gold_head_rel_shaking_tag, pred_head_rel_shaking_tag = batch_gold_head_rel_shaking_tag[ind], batch_pred_head_rel_shaking_tag[ind]\n",
    "        gold_tail_rel_shaking_tag, pred_tail_rel_shaking_tag = batch_gold_tail_rel_shaking_tag[ind], batch_pred_tail_rel_shaking_tag[ind]\n",
    "        \n",
    "        pred_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "                                                  pred_ent_shaking_tag, \n",
    "                                                  pred_head_rel_shaking_tag, \n",
    "                                                  pred_tail_rel_shaking_tag, \n",
    "                                                  offset_map)\n",
    "        gold_rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "                                                  gold_ent_shaking_tag, \n",
    "                                                  gold_head_rel_shaking_tag, \n",
    "                                                  gold_tail_rel_shaking_tag, \n",
    "                                                  offset_map)\n",
    "\n",
    "        gold_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in gold_rel_list])\n",
    "        pred_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in pred_rel_list])\n",
    "        \n",
    "        for rel_str in pred_rel_set:\n",
    "            if rel_str in gold_rel_set:\n",
    "                correct_num += 1\n",
    "        \n",
    "        pred_num += len(gold_rel_set)\n",
    "        gold_num += len(pred_rel_set)\n",
    "        \n",
    "    return correct_num, pred_num, gold_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(correct_num, pred_num, gold_num):\n",
    "    minimini = 1e-10\n",
    "    precision = correct_num / (pred_num + minimini)\n",
    "    recall = correct_num / (gold_num + minimini)\n",
    "    f1 = 2 * precision * recall / (precision + recall + minimini)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train step\n",
    "def train_step(batch_train_data, optimizer):\n",
    "    text_id_list, text_list, batch_input_ids, \\\n",
    "    batch_attention_mask, batch_token_type_ids, \\\n",
    "    offset_map_list, batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_train_data\n",
    "    \n",
    "    batch_input_ids, \\\n",
    "    batch_attention_mask, \\\n",
    "    batch_token_type_ids, \\\n",
    "    batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, \\\n",
    "    batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                              batch_attention_mask.to(device), \n",
    "                              batch_token_type_ids.to(device), \n",
    "                              batch_ent_shaking_tag.to(device), \n",
    "                              batch_head_rel_shaking_tag.to(device), \n",
    "                              batch_tail_rel_shaking_tag.to(device)\n",
    "                             )\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    ent_shaking_outputs, \\\n",
    "    head_rel_shaking_outputs, \\\n",
    "    tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                              batch_attention_mask, \n",
    "                                              batch_token_type_ids, \n",
    "                                             )\n",
    "\n",
    "    loss = loss_func(ent_shaking_outputs, batch_ent_shaking_tag) + \\\n",
    "            len(rel2id) * loss_func(head_rel_shaking_outputs, batch_head_rel_shaking_tag) + \\\n",
    "            len(rel2id) * loss_func(tail_rel_shaking_outputs, batch_tail_rel_shaking_tag) / (2 * len(rel2id) + 1)\n",
    "    \n",
    "    # bp time: 2s\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    ent_sample_acc = get_sample_accuracy(ent_shaking_outputs, \n",
    "                                          batch_ent_shaking_tag)\n",
    "    head_rel_sample_acc = get_sample_accuracy(head_rel_shaking_outputs, \n",
    "                                             batch_head_rel_shaking_tag)\n",
    "    tail_rel_sample_acc = get_sample_accuracy(tail_rel_shaking_outputs, \n",
    "                                             batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    return loss.item(), ent_sample_acc.item(), head_rel_sample_acc.item(), tail_rel_sample_acc.item()\n",
    "\n",
    "# valid step\n",
    "def valid_step(batch_valid_data):\n",
    "    text_id_list, text_list, batch_input_ids, \\\n",
    "    batch_attention_mask, batch_token_type_ids, \\\n",
    "    offset_map_list, batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, batch_tail_rel_shaking_tag = batch_valid_data\n",
    "    \n",
    "    batch_input_ids, \\\n",
    "    batch_attention_mask, \\\n",
    "    batch_token_type_ids, \\\n",
    "    batch_ent_shaking_tag, \\\n",
    "    batch_head_rel_shaking_tag, \\\n",
    "    batch_tail_rel_shaking_tag = (batch_input_ids.to(device), \n",
    "                              batch_attention_mask.to(device), \n",
    "                              batch_token_type_ids.to(device), \n",
    "                              batch_ent_shaking_tag.to(device), \n",
    "                              batch_head_rel_shaking_tag.to(device), \n",
    "                              batch_tail_rel_shaking_tag.to(device)\n",
    "                             )\n",
    "    with torch.no_grad():\n",
    "        ent_shaking_outputs, \\\n",
    "        head_rel_shaking_outputs, \\\n",
    "        tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                                  batch_attention_mask, \n",
    "                                                  batch_token_type_ids, \n",
    "                                                 )\n",
    "    \n",
    "    ent_sample_acc = get_sample_accuracy(ent_shaking_outputs, \n",
    "                                          batch_ent_shaking_tag)\n",
    "    head_rel_sample_acc = get_sample_accuracy(head_rel_shaking_outputs, \n",
    "                                             batch_head_rel_shaking_tag)\n",
    "    tail_rel_sample_acc = get_sample_accuracy(tail_rel_shaking_outputs, \n",
    "                                             batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    rel_cpg = get_rel_cpg(text_list, offset_map_list, \n",
    "                            ent_shaking_outputs,\n",
    "                            head_rel_shaking_outputs,\n",
    "                            tail_rel_shaking_outputs,\n",
    "                            batch_ent_shaking_tag,\n",
    "                            batch_head_rel_shaking_tag,\n",
    "                            batch_tail_rel_shaking_tag)\n",
    "    \n",
    "    return ent_sample_acc.item(), head_rel_sample_acc.item(), tail_rel_sample_acc.item(), rel_cpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = 0.\n",
    "def train_n_valid(train_dataloader, dev_dataloader, optimizer, scheduler, num_epoch):  \n",
    "    def train(dataloader, ep):\n",
    "        # train\n",
    "        rel_extractor.train()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        start_lr = optimizer.param_groups[0]['lr']\n",
    "        total_loss, total_ent_sample_acc, total_head_rel_sample_acc, total_tail_rel_sample_acc = 0., 0., 0., 0.\n",
    "        for batch_ind, batch_train_data in enumerate(dataloader):\n",
    "            t_batch = time.time()\n",
    "            loss, ent_sample_acc, head_rel_sample_acc, tail_rel_sample_acc = train_step(batch_train_data, optimizer)\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_ent_sample_acc += ent_sample_acc\n",
    "            total_head_rel_sample_acc += head_rel_sample_acc\n",
    "            total_tail_rel_sample_acc += tail_rel_sample_acc\n",
    "            \n",
    "            avg_loss = total_loss / (batch_ind + 1)\n",
    "            avg_ent_sample_acc = total_ent_sample_acc / (batch_ind + 1)\n",
    "            avg_head_rel_sample_acc = total_head_rel_sample_acc / (batch_ind + 1)\n",
    "            avg_tail_rel_sample_acc = total_tail_rel_sample_acc / (batch_ind + 1)\n",
    "            \n",
    "            batch_print_format = \"\\rEpoch: {}/{}, batch: {}/{}, train_loss: {}, \" + \\\n",
    "                                \"t_ent_sample_acc: {}, t_head_rel_sample_acc: {}, t_tail_rel_sample_acc: {},\" + \\\n",
    "                                 \"lr: {}, batch_time: {}, total_time: {} -------------\"\n",
    "                    \n",
    "            print(batch_print_format.format(ep + 1, num_epoch, \n",
    "                                            batch_ind + 1, len(dataloader), \n",
    "                                            avg_loss, \n",
    "                                            avg_ent_sample_acc,\n",
    "                                            avg_head_rel_sample_acc,\n",
    "                                            avg_tail_rel_sample_acc,\n",
    "                                            optimizer.param_groups[0]['lr'],\n",
    "                                            time.time() - t_batch,\n",
    "                                            time.time() - t_ep,\n",
    "                                           ), end=\"\")\n",
    "        log_format = \"Epoch: {}/{}, train_sample_acc(ent, head_rel, tail_rel): ({},{},{}), start_lr:{}, end_lr: {}, ep_time: {}\"\n",
    "        logger.info(log_format.format(ep + 1, num_epoch, \n",
    "                                      avg_ent_sample_acc, \n",
    "                                      avg_head_rel_sample_acc, \n",
    "                                      avg_tail_rel_sample_acc, \n",
    "                                      start_lr, \n",
    "                                      optimizer.param_groups[0]['lr'], \n",
    "                                      time.time() - t_ep))\n",
    "    def valid(dataloader, ep):\n",
    "        # valid\n",
    "        rel_extractor.eval()\n",
    "        \n",
    "        t_ep = time.time()\n",
    "        total_ent_sample_acc, total_head_rel_sample_acc, total_tail_rel_sample_acc = 0., 0., 0.\n",
    "        total_rel_correct_num, total_rel_pred_num, total_rel_gold_num = 0, 0, 0\n",
    "        for batch_ind, batch_valid_data in enumerate(tqdm(dataloader, desc = \"Validating\")):\n",
    "            ent_sample_acc, head_rel_sample_acc, tail_rel_sample_acc, rel_cpg = valid_step(batch_valid_data)\n",
    "\n",
    "            total_ent_sample_acc += ent_sample_acc\n",
    "            total_head_rel_sample_acc += head_rel_sample_acc\n",
    "            total_tail_rel_sample_acc += tail_rel_sample_acc\n",
    "            \n",
    "            total_rel_correct_num += rel_cpg[0]\n",
    "            total_rel_pred_num += rel_cpg[1]\n",
    "            total_rel_gold_num += rel_cpg[2]\n",
    "\n",
    "        avg_ent_sample_acc = total_ent_sample_acc / len(dataloader)\n",
    "        avg_head_rel_sample_acc = total_head_rel_sample_acc / len(dataloader)\n",
    "        avg_tail_rel_sample_acc = total_tail_rel_sample_acc / len(dataloader)\n",
    "        \n",
    "        rel_prf = get_scores(total_rel_correct_num, total_rel_pred_num, total_rel_gold_num)\n",
    "             \n",
    "        print_format = \"Epoch: {}/{}, val_ent_sample_acc: {}, \" + \\\n",
    "                        \"val_head_rel_sample_acc: {}, val_tail_rel_sample_acc: {}\\n\" + \\\n",
    "                        \"val_rel_prec: {}, val_rel_rec: {}, val_rel_f1: {},\\n\" + \\\n",
    "                        \"val_time: {}\"\n",
    "        logger.info(print_format.format(ep + 1, num_epoch,  \n",
    "                                  avg_ent_sample_acc,\n",
    "                                  avg_head_rel_sample_acc,\n",
    "                                  avg_tail_rel_sample_acc,\n",
    "                                  *rel_prf, \n",
    "                                  time.time() - t_ep,\n",
    "                                 ))\n",
    "        return rel_prf[2]\n",
    "        \n",
    "    for ep in range(num_epoch):\n",
    "        train(train_dataloader, ep)   \n",
    "        valid_f1 = valid(dev_dataloader, ep)\n",
    "        \n",
    "        global max_f1\n",
    "        if valid_f1 >= max_f1: \n",
    "            max_f1 = valid_f1\n",
    "            if valid_f1 > 0.7: # save the best model\n",
    "                file_num = len(glob.glob(model_state_dict_dir + \"/*.pt\"))\n",
    "                torch.save(rel_extractor.state_dict(), os.path.join(model_state_dict_dir, \"model_state_dict_{}.pt\".format(file_num))) \n",
    "#                 torch.save(scheduler.state_dict(), os.path.join(schedule_state_dict_dir, \"scheduler_state_dict_{}.pt\".format(file_num))) \n",
    "        print(\"Current avf_f1: {}, Best f1: {}\".format(valid_f1, max_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rel_extractor.state_dict(), os.path.join(model_state_dict_dir, \"model_state_dict_{}.pt\".format(0))) \n",
    "# torch.save(scheduler.state_dict(), os.path.join(schedule_state_dict_dir, \"scheduler_state_dict_{}.pt\".format(0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_state_path(state_dir):\n",
    "    max_file_num = -1\n",
    "    last_state_path = None\n",
    "    for path in glob.glob(state_dir + \"/*.pt\"):\n",
    "        file_num = re.search(\"state_dict_(\\d+)\\.pt\", path).group(1)\n",
    "        if int(file_num) > max_file_num:\n",
    "            max_file_num = int(file_num)\n",
    "            last_state_path = path\n",
    "    return last_state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_path(state_dict_dir, state_dict_num):\n",
    "    return os.path.join(state_dict_dir, \"model_state_dict_{}.pt\".format(state_dict_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing dataloader...\n",
      "dataloaders done!\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "print(\"preparing dataloader...\")\n",
    "train_dataloader, \\\n",
    "dev_dataloader = get_train_dev_dataloader_gen(indexed_train_data, \n",
    "                                            indexed_valid_data, \n",
    "                                            batch_size, \n",
    "                                            )\n",
    "print(\"dataloaders done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "init_learning_rate = 5e-5\n",
    "optimizer = torch.optim.Adam(rel_extractor.parameters(), lr = init_learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, len(train_dataloader) * 2)\n",
    "\n",
    "# decay_rate = 0.99\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------model state model_state_dict_12.pt loaded ----------------\n",
      "------------scheduler state scheduler_state_dict_12.pt loaded ----------------\n",
      "Epoch: 1/50, batch: 76/2432, train_loss: 1.3673732551473294e-05, t_ent_sample_acc: 0.9906798326655438, t_head_rel_sample_acc: 0.9813596637625444, t_tail_rel_sample_acc: 0.9835526425587503,lr: 4.997067350062796e-05, batch_time: 1.6363730430603027, total_time: 134.43712329864502 --------------"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/yubowen/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-46fd98b91d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------scheduler state {} loaded ----------------\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler_last_state_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_n_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-6538b9a28248>\u001b[0m in \u001b[0;36mtrain_n_valid\u001b[0;34m(train_dataloader, dev_dataloader, optimizer, scheduler, num_epoch)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-6538b9a28248>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, ep)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_train_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment_sample_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_rel_sample_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail_rel_sample_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-037a18448ad0>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch_train_data, optimizer)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# bp time: 2s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 50\n",
    "# load the last best state (if any)\n",
    "model_all_state_paths = glob.glob(model_state_dict_dir + \"/*.pt\")\n",
    "if len(model_all_state_paths) > 0:\n",
    "    model_last_state_path = get_last_state_path(model_state_dict_dir)\n",
    "    rel_extractor.load_state_dict(torch.load(model_last_state_path))\n",
    "    print(\"------------model state {} loaded ----------------\".format(model_last_state_path.split(\"/\")[-1]))\n",
    "    \n",
    "scheduler_last_state_path = get_last_state_path(schedule_state_dict_dir)  \n",
    "if scheduler_last_state_path is not None:\n",
    "    scheduler.load_state_dict(torch.load(scheduler_last_state_path))\n",
    "    print(\"------------scheduler state {} loaded ----------------\".format(scheduler_last_state_path.split(\"/\")[-1]))\n",
    "\n",
    "train_n_valid(train_dataloader, dev_dataloader, optimizer, scheduler, epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------model state model_state_dict_12.pt loaded ----------------\n"
     ]
    }
   ],
   "source": [
    "model_state_path = get_last_state_path(model_state_dict_dir)\n",
    "# model_state_path = get_state_path(model_state_dict_dir, 16)\n",
    "rel_extractor.load_state_dict(torch.load(model_state_path))\n",
    "rel_extractor.eval()\n",
    "print(\"------------model state {} loaded ----------------\".format(model_state_path.split(\"/\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_duplicates(rel_list):\n",
    "    rel_memory_set = set()\n",
    "    filtered_rel_list = []\n",
    "    for rel in rel_list:\n",
    "        rel_memory = \"{}\\u2E80\\{}\\u2E80\\{}\\u2E80\\{}\\u2E80{}\".format(*rel.values())\n",
    "        if rel_memory not in rel_memory_set:\n",
    "            filtered_rel_list.append(rel)\n",
    "            rel_memory_set.add(rel_memory)\n",
    "    return filtered_rel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(short_test_data):\n",
    "    '''\n",
    "    short_test_data: seq_len <= max_seq_len\n",
    "    '''\n",
    "    indexed_test_data = get_indexed_train_valid_data(short_test_data)\n",
    "    test_dataloader = DataLoader(MyDataset(indexed_test_data), \n",
    "                              batch_size = batch_size, \n",
    "                              shuffle = False, \n",
    "                              num_workers = 0,\n",
    "                              drop_last = False,\n",
    "                              collate_fn = generate_pred_batch,\n",
    "                             )\n",
    "    short_pred_sample_list = []\n",
    "    for batch_test_data in tqdm(test_dataloader, desc = \"Predicting\"):\n",
    "        text_id_list, text_list, batch_input_ids, \\\n",
    "        batch_attention_mask, batch_token_type_ids, \\\n",
    "        offset_map_list = batch_test_data\n",
    "\n",
    "        batch_input_ids, \\\n",
    "        batch_attention_mask, \\\n",
    "        batch_token_type_ids = (batch_input_ids.to(device), \n",
    "                                  batch_attention_mask.to(device), \n",
    "                                  batch_token_type_ids.to(device)\n",
    "                                 )\n",
    "        with torch.no_grad():\n",
    "            batch_ent_shaking_outputs, \\\n",
    "            batch_head_rel_shaking_outputs, \\\n",
    "            batch_tail_rel_shaking_outputs = rel_extractor(batch_input_ids, \n",
    "                                                              batch_attention_mask, \n",
    "                                                              batch_token_type_ids, \n",
    "                                                             )\n",
    "\n",
    "        batch_ent_shaking_tag, \\\n",
    "        batch_head_rel_shaking_tag, \\\n",
    "        batch_tail_rel_shaking_tag = torch.argmax(batch_ent_shaking_outputs, dim = -1), \\\n",
    "                                     torch.argmax(batch_head_rel_shaking_outputs, dim = -1), \\\n",
    "                                     torch.argmax(batch_tail_rel_shaking_outputs, dim = -1)\n",
    "\n",
    "        for ind in range(len(text_list)):\n",
    "            text, offset_map = text_list[ind], offset_map_list[ind]\n",
    "            ent_shaking_tag, \\\n",
    "            head_rel_shaking_tag, \\\n",
    "            tail_rel_shaking_tag = batch_ent_shaking_tag[ind], \\\n",
    "                                    batch_head_rel_shaking_tag[ind], \\\n",
    "                                    batch_tail_rel_shaking_tag[ind]\n",
    "            rel_list = handshaking_tagger.decode_rel_fr_shaking_tag(text, \n",
    "                                                  ent_shaking_tag, \n",
    "                                                  head_rel_shaking_tag, \n",
    "                                                  tail_rel_shaking_tag, \n",
    "                                                  offset_map)\n",
    "            short_pred_sample_list.append({\n",
    "                \"text\": text,\n",
    "                \"id\": text_id_list[ind],\n",
    "                \"relation_list\": rel_list,\n",
    "            })\n",
    "    # merge\n",
    "    text_id2rel_list = {}\n",
    "    for sample in short_pred_sample_list:\n",
    "        text_id = sample[\"id\"]\n",
    "        if text_id not in text_id2rel_list:\n",
    "            text_id2rel_list[text_id] = sample[\"relation_list\"]\n",
    "        else:\n",
    "            text_id2rel_list[text_id].extend(sample[\"relation_list\"])\n",
    "\n",
    "    text_id2text = {sample[\"id\"]:sample[\"text\"] for sample in test_data}\n",
    "    merged_pred_sample_list = []\n",
    "    for text_id, rel_list in text_id2rel_list.items():\n",
    "        merged_pred_sample_list.append({\n",
    "            \"id\": text_id,\n",
    "            \"text\": text_id2text[text_id],\n",
    "            \"relation_list\": filter_duplicates(rel_list),\n",
    "        })\n",
    "    return merged_pred_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate indexed train or valid data: 5185it [00:03, 1616.51it/s]\n",
      "Predicting: 100%|██████████| 217/217 [01:15<00:00,  2.89it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_sample_list = predict(short_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4944"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in pred_sample_list if len(s[\"relation_list\"]) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id2gold_n_pred = {}\n",
    "for sample in test_data:\n",
    "    text_id = sample[\"id\"]\n",
    "    text_id2gold_n_pred[text_id] = {\n",
    "        \"gold_relation_list\": sample[\"relation_list\"],\n",
    "    }\n",
    "def get_test_prf(pred_sample_list):\n",
    "    for sample in pred_sample_list:\n",
    "        text_id = sample[\"id\"]\n",
    "        text_id2gold_n_pred[text_id][\"pred_relation_list\"] = sample[\"relation_list\"]\n",
    "\n",
    "    correct_num, pred_num, gold_num = 0, 0, 0\n",
    "    for gold_n_pred in text_id2gold_n_pred.values():\n",
    "        gold_rel_list = gold_n_pred[\"gold_relation_list\"]\n",
    "        pred_rel_list = gold_n_pred[\"pred_relation_list\"]\n",
    "        gold_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in gold_rel_list])\n",
    "        pred_rel_set = set([\"{}\\u2E80{}\\u2E80{}\".format(rel[\"subject\"], rel[\"predicate\"], rel[\"object\"]) for rel in pred_rel_list])\n",
    "\n",
    "        for rel_str in pred_rel_set:\n",
    "            if rel_str in gold_rel_set:\n",
    "                correct_num += 1\n",
    "\n",
    "        pred_num += len(gold_rel_set)\n",
    "        gold_num += len(pred_rel_set)\n",
    "\n",
    "    prf = get_scores(correct_num, pred_num, gold_num)\n",
    "#     print(prf)\n",
    "    return prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9275862068965403, 0.9109820996613339, 0.9192091773969052)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model state 16: (0.9112068965517129, 0.9034188034187924, 0.9072961372890456)\n",
    "# model state 17: (0.9060344827586095, 0.9096191889218483, 0.9078232970872052)\n",
    "# 18: (0.9178571428571316, 0.904600072824361, 0.9111803899493801)\n",
    "get_test_prf(pred_sample_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
